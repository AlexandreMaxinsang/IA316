{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dropout, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third environmement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['action_history', 'nb_items', 'nb_users', 'next_state', 'rewards_history', 'state_history'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attributes fa\n",
    "USER_ID = 'IAHIZPIW80WPGDW7P7JE'\n",
    "BASE_URL = \"http://35.180.178.243\"\n",
    "url_reset = BASE_URL + \"/reset\"\n",
    "url_predict = BASE_URL + \"/predict\"\n",
    "params = {\"user_id\" : USER_ID}\n",
    "\n",
    "def load_data(url_reset,params) :\n",
    "    r = requests.get(url=url_reset, params=params)\n",
    "    data = r.json()\n",
    "    return data\n",
    "\n",
    "data = load_data(url_reset,params)\n",
    "nb_users = data[\"nb_users\"]\n",
    "nb_items = data[\"nb_items\"]\n",
    "next_state = data[\"next_state\"]\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #See the request predict from our API\n",
    "# params = {\"user_id\" : user_id,\"recommended_item\": 2}\n",
    "# requests.get(url=url_predict, params=params).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "      <th>state_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[5, 0, 995.4367425100899, -0.0168718993729635...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[58, 0, 995.4367425100899, 1.5616172497663623...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>647.932910</td>\n",
       "      <td>[[92, 0, 995.4367425100899, 0.8019868269580972...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[41, 0, 995.4367425100899, 0.9170586867255156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>178.207535</td>\n",
       "      <td>[[94, 0, 995.4367425100899, 0.731733947245598,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_history  rewards_history  \\\n",
       "0              10         0.000000   \n",
       "1              14         0.000000   \n",
       "2               4       647.932910   \n",
       "3               6         0.000000   \n",
       "4              23       178.207535   \n",
       "\n",
       "                                       state_history  \n",
       "0  [[5, 0, 995.4367425100899, -0.0168718993729635...  \n",
       "1  [[58, 0, 995.4367425100899, 1.5616172497663623...  \n",
       "2  [[92, 0, 995.4367425100899, 0.8019868269580972...  \n",
       "3  [[41, 0, 995.4367425100899, 0.9170586867255156...  \n",
       "4  [[94, 0, 995.4367425100899, 0.731733947245598,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklisted_set = set((\"next_state\",\"nb_items\",\"nb_users\"))\n",
    "new_dict = {key : value for key, value in data.items() if key not in blacklisted_set}\n",
    "\n",
    "df = pd.DataFrame(new_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.895000</td>\n",
       "      <td>197.218886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.629386</td>\n",
       "      <td>321.037754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>336.974413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>995.436743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       action_history  rewards_history\n",
       "count      200.000000       200.000000\n",
       "mean        14.895000       197.218886\n",
       "std          8.629386       321.037754\n",
       "min          0.000000         0.000000\n",
       "25%          7.750000         0.000000\n",
       "50%         15.000000         0.000000\n",
       "75%         22.000000       336.974413\n",
       "max         29.000000       995.436743"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action_history     133\n",
       "rewards_history    133\n",
       "state_history      133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rewards_history']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>995.436743</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-0.122741</td>\n",
       "      <td>-0.859929</td>\n",
       "      <td>3.548400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>268.197275</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.804975</td>\n",
       "      <td>2.795424</td>\n",
       "      <td>2.349247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>76.225432</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>2.233305</td>\n",
       "      <td>0.514133</td>\n",
       "      <td>-0.756044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>459.774176</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-0.976587</td>\n",
       "      <td>1.686933</td>\n",
       "      <td>0.222204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>647.932910</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>3.241630</td>\n",
       "      <td>2.866647</td>\n",
       "      <td>0.576906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>119.735821</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-0.391206</td>\n",
       "      <td>0.835439</td>\n",
       "      <td>-1.345818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>775.443156</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.000608</td>\n",
       "      <td>0.572089</td>\n",
       "      <td>0.905308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>35.822297</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.160343</td>\n",
       "      <td>1.527066</td>\n",
       "      <td>0.430796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>519.866211</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.418672</td>\n",
       "      <td>-0.628954</td>\n",
       "      <td>-0.158545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>743.797849</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-1.040818</td>\n",
       "      <td>1.852715</td>\n",
       "      <td>1.748791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>860.300459</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.637465</td>\n",
       "      <td>3.547860</td>\n",
       "      <td>0.056403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>443.473720</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-0.775018</td>\n",
       "      <td>-1.412762</td>\n",
       "      <td>0.853551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>373.011060</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>2.515712</td>\n",
       "      <td>1.624230</td>\n",
       "      <td>2.475240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>822.851561</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.641863</td>\n",
       "      <td>3.415451</td>\n",
       "      <td>1.380912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>716.198821</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>2.585274</td>\n",
       "      <td>1.745232</td>\n",
       "      <td>-1.891818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>363.628398</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-1.037178</td>\n",
       "      <td>1.493053</td>\n",
       "      <td>0.348718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>875.237043</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.384317</td>\n",
       "      <td>1.993438</td>\n",
       "      <td>1.269448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>132.398118</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.253016</td>\n",
       "      <td>1.763324</td>\n",
       "      <td>-0.323786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>843.215136</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.535862</td>\n",
       "      <td>0.907044</td>\n",
       "      <td>0.514391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>193.390014</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.046214</td>\n",
       "      <td>1.247706</td>\n",
       "      <td>0.504765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>242.767664</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.547506</td>\n",
       "      <td>-0.476549</td>\n",
       "      <td>1.546758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>612.712897</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.130008</td>\n",
       "      <td>2.099182</td>\n",
       "      <td>0.485266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>99.634472</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.540315</td>\n",
       "      <td>1.458051</td>\n",
       "      <td>1.231536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>178.207535</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.349523</td>\n",
       "      <td>0.411883</td>\n",
       "      <td>0.767101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>511.660566</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.194533</td>\n",
       "      <td>2.650356</td>\n",
       "      <td>1.403805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>811.585437</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-0.424721</td>\n",
       "      <td>-0.133137</td>\n",
       "      <td>1.250085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>911.304950</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>1.960973</td>\n",
       "      <td>0.731633</td>\n",
       "      <td>2.912326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>724.190701</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>0.233370</td>\n",
       "      <td>-0.216591</td>\n",
       "      <td>1.224812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>485.387763</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>-0.241311</td>\n",
       "      <td>-0.811203</td>\n",
       "      <td>-0.830379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>336.974413</td>\n",
       "      <td>-0.016872</td>\n",
       "      <td>0.248659</td>\n",
       "      <td>2.804049</td>\n",
       "      <td>-0.265077</td>\n",
       "      <td>1.100967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>63</td>\n",
       "      <td>28</td>\n",
       "      <td>485.387763</td>\n",
       "      <td>1.499728</td>\n",
       "      <td>-0.310474</td>\n",
       "      <td>-0.241311</td>\n",
       "      <td>-0.811203</td>\n",
       "      <td>0.626879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>63</td>\n",
       "      <td>29</td>\n",
       "      <td>336.974413</td>\n",
       "      <td>1.499728</td>\n",
       "      <td>-0.310474</td>\n",
       "      <td>2.804049</td>\n",
       "      <td>-0.265077</td>\n",
       "      <td>1.354912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5919</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>995.436743</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-0.122741</td>\n",
       "      <td>-0.859929</td>\n",
       "      <td>1.337547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>268.197275</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.804975</td>\n",
       "      <td>2.795424</td>\n",
       "      <td>-0.429446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>76.225432</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>2.233305</td>\n",
       "      <td>0.514133</td>\n",
       "      <td>1.842937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>459.774176</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-0.976587</td>\n",
       "      <td>1.686933</td>\n",
       "      <td>0.214922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>647.932910</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>3.241630</td>\n",
       "      <td>2.866647</td>\n",
       "      <td>0.827395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>119.735821</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-0.391206</td>\n",
       "      <td>0.835439</td>\n",
       "      <td>-0.177918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>775.443156</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.000608</td>\n",
       "      <td>0.572089</td>\n",
       "      <td>0.354987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>35.822297</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>0.160343</td>\n",
       "      <td>1.527066</td>\n",
       "      <td>0.541908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5927</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>519.866211</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>0.418672</td>\n",
       "      <td>-0.628954</td>\n",
       "      <td>0.724899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>743.797849</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-1.040818</td>\n",
       "      <td>1.852715</td>\n",
       "      <td>-0.379927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>860.300459</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.637465</td>\n",
       "      <td>3.547860</td>\n",
       "      <td>3.117360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>443.473720</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-0.775018</td>\n",
       "      <td>-1.412762</td>\n",
       "      <td>0.090306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>373.011060</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>2.515712</td>\n",
       "      <td>1.624230</td>\n",
       "      <td>1.058687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>822.851561</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>0.641863</td>\n",
       "      <td>3.415451</td>\n",
       "      <td>3.641658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>716.198821</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>2.585274</td>\n",
       "      <td>1.745232</td>\n",
       "      <td>2.345152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>363.628398</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-1.037178</td>\n",
       "      <td>1.493053</td>\n",
       "      <td>0.879841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>875.237043</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.384317</td>\n",
       "      <td>1.993438</td>\n",
       "      <td>1.470525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>132.398118</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.253016</td>\n",
       "      <td>1.763324</td>\n",
       "      <td>0.514911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>843.215136</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>0.535862</td>\n",
       "      <td>0.907044</td>\n",
       "      <td>1.515825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>193.390014</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.046214</td>\n",
       "      <td>1.247706</td>\n",
       "      <td>0.972468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>242.767664</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>0.547506</td>\n",
       "      <td>-0.476549</td>\n",
       "      <td>1.069763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>99.634472</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.540315</td>\n",
       "      <td>1.458051</td>\n",
       "      <td>1.049182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>178.207535</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.349523</td>\n",
       "      <td>0.411883</td>\n",
       "      <td>-0.022299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>511.660566</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.194533</td>\n",
       "      <td>2.650356</td>\n",
       "      <td>1.192926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>811.585437</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-0.424721</td>\n",
       "      <td>-0.133137</td>\n",
       "      <td>1.381152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5944</th>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>911.304950</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>1.960973</td>\n",
       "      <td>0.731633</td>\n",
       "      <td>-1.656335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5945</th>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>724.190701</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>0.233370</td>\n",
       "      <td>-0.216591</td>\n",
       "      <td>1.206601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5946</th>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>485.387763</td>\n",
       "      <td>-0.668064</td>\n",
       "      <td>0.978303</td>\n",
       "      <td>-0.241311</td>\n",
       "      <td>-0.811203</td>\n",
       "      <td>0.853487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5947 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id       price        v1        v2        v3        v4  \\\n",
       "0           5        0  995.436743 -0.016872  0.248659 -0.122741 -0.859929   \n",
       "1           5        1  268.197275 -0.016872  0.248659  1.804975  2.795424   \n",
       "2           5        2   76.225432 -0.016872  0.248659  2.233305  0.514133   \n",
       "3           5        3  459.774176 -0.016872  0.248659 -0.976587  1.686933   \n",
       "4           5        4  647.932910 -0.016872  0.248659  3.241630  2.866647   \n",
       "5           5        5  119.735821 -0.016872  0.248659 -0.391206  0.835439   \n",
       "6           5        6  775.443156 -0.016872  0.248659  1.000608  0.572089   \n",
       "7           5        7   35.822297 -0.016872  0.248659  0.160343  1.527066   \n",
       "8           5        8  519.866211 -0.016872  0.248659  0.418672 -0.628954   \n",
       "9           5        9  743.797849 -0.016872  0.248659 -1.040818  1.852715   \n",
       "10          5       10  860.300459 -0.016872  0.248659  1.637465  3.547860   \n",
       "11          5       11  443.473720 -0.016872  0.248659 -0.775018 -1.412762   \n",
       "12          5       12  373.011060 -0.016872  0.248659  2.515712  1.624230   \n",
       "13          5       13  822.851561 -0.016872  0.248659  0.641863  3.415451   \n",
       "14          5       14  716.198821 -0.016872  0.248659  2.585274  1.745232   \n",
       "15          5       15  363.628398 -0.016872  0.248659 -1.037178  1.493053   \n",
       "16          5       16  875.237043 -0.016872  0.248659  1.384317  1.993438   \n",
       "17          5       17  132.398118 -0.016872  0.248659  1.253016  1.763324   \n",
       "18          5       18  843.215136 -0.016872  0.248659  0.535862  0.907044   \n",
       "19          5       19  193.390014 -0.016872  0.248659  1.046214  1.247706   \n",
       "20          5       20  242.767664 -0.016872  0.248659  0.547506 -0.476549   \n",
       "21          5       21  612.712897 -0.016872  0.248659  1.130008  2.099182   \n",
       "22          5       22   99.634472 -0.016872  0.248659  1.540315  1.458051   \n",
       "23          5       23  178.207535 -0.016872  0.248659  1.349523  0.411883   \n",
       "24          5       24  511.660566 -0.016872  0.248659  1.194533  2.650356   \n",
       "25          5       25  811.585437 -0.016872  0.248659 -0.424721 -0.133137   \n",
       "26          5       26  911.304950 -0.016872  0.248659  1.960973  0.731633   \n",
       "27          5       27  724.190701 -0.016872  0.248659  0.233370 -0.216591   \n",
       "28          5       28  485.387763 -0.016872  0.248659 -0.241311 -0.811203   \n",
       "29          5       29  336.974413 -0.016872  0.248659  2.804049 -0.265077   \n",
       "...       ...      ...         ...       ...       ...       ...       ...   \n",
       "5917       63       28  485.387763  1.499728 -0.310474 -0.241311 -0.811203   \n",
       "5918       63       29  336.974413  1.499728 -0.310474  2.804049 -0.265077   \n",
       "5919       32        0  995.436743 -0.668064  0.978303 -0.122741 -0.859929   \n",
       "5920       32        1  268.197275 -0.668064  0.978303  1.804975  2.795424   \n",
       "5921       32        2   76.225432 -0.668064  0.978303  2.233305  0.514133   \n",
       "5922       32        3  459.774176 -0.668064  0.978303 -0.976587  1.686933   \n",
       "5923       32        4  647.932910 -0.668064  0.978303  3.241630  2.866647   \n",
       "5924       32        5  119.735821 -0.668064  0.978303 -0.391206  0.835439   \n",
       "5925       32        6  775.443156 -0.668064  0.978303  1.000608  0.572089   \n",
       "5926       32        7   35.822297 -0.668064  0.978303  0.160343  1.527066   \n",
       "5927       32        8  519.866211 -0.668064  0.978303  0.418672 -0.628954   \n",
       "5928       32        9  743.797849 -0.668064  0.978303 -1.040818  1.852715   \n",
       "5929       32       10  860.300459 -0.668064  0.978303  1.637465  3.547860   \n",
       "5930       32       11  443.473720 -0.668064  0.978303 -0.775018 -1.412762   \n",
       "5931       32       12  373.011060 -0.668064  0.978303  2.515712  1.624230   \n",
       "5932       32       13  822.851561 -0.668064  0.978303  0.641863  3.415451   \n",
       "5933       32       14  716.198821 -0.668064  0.978303  2.585274  1.745232   \n",
       "5934       32       15  363.628398 -0.668064  0.978303 -1.037178  1.493053   \n",
       "5935       32       16  875.237043 -0.668064  0.978303  1.384317  1.993438   \n",
       "5936       32       17  132.398118 -0.668064  0.978303  1.253016  1.763324   \n",
       "5937       32       18  843.215136 -0.668064  0.978303  0.535862  0.907044   \n",
       "5938       32       19  193.390014 -0.668064  0.978303  1.046214  1.247706   \n",
       "5939       32       20  242.767664 -0.668064  0.978303  0.547506 -0.476549   \n",
       "5940       32       22   99.634472 -0.668064  0.978303  1.540315  1.458051   \n",
       "5941       32       23  178.207535 -0.668064  0.978303  1.349523  0.411883   \n",
       "5942       32       24  511.660566 -0.668064  0.978303  1.194533  2.650356   \n",
       "5943       32       25  811.585437 -0.668064  0.978303 -0.424721 -0.133137   \n",
       "5944       32       26  911.304950 -0.668064  0.978303  1.960973  0.731633   \n",
       "5945       32       27  724.190701 -0.668064  0.978303  0.233370 -0.216591   \n",
       "5946       32       28  485.387763 -0.668064  0.978303 -0.241311 -0.811203   \n",
       "\n",
       "            v5  \n",
       "0     3.548400  \n",
       "1     2.349247  \n",
       "2    -0.756044  \n",
       "3     0.222204  \n",
       "4     0.576906  \n",
       "5    -1.345818  \n",
       "6     0.905308  \n",
       "7     0.430796  \n",
       "8    -0.158545  \n",
       "9     1.748791  \n",
       "10    0.056403  \n",
       "11    0.853551  \n",
       "12    2.475240  \n",
       "13    1.380912  \n",
       "14   -1.891818  \n",
       "15    0.348718  \n",
       "16    1.269448  \n",
       "17   -0.323786  \n",
       "18    0.514391  \n",
       "19    0.504765  \n",
       "20    1.546758  \n",
       "21    0.485266  \n",
       "22    1.231536  \n",
       "23    0.767101  \n",
       "24    1.403805  \n",
       "25    1.250085  \n",
       "26    2.912326  \n",
       "27    1.224812  \n",
       "28   -0.830379  \n",
       "29    1.100967  \n",
       "...        ...  \n",
       "5917  0.626879  \n",
       "5918  1.354912  \n",
       "5919  1.337547  \n",
       "5920 -0.429446  \n",
       "5921  1.842937  \n",
       "5922  0.214922  \n",
       "5923  0.827395  \n",
       "5924 -0.177918  \n",
       "5925  0.354987  \n",
       "5926  0.541908  \n",
       "5927  0.724899  \n",
       "5928 -0.379927  \n",
       "5929  3.117360  \n",
       "5930  0.090306  \n",
       "5931  1.058687  \n",
       "5932  3.641658  \n",
       "5933  2.345152  \n",
       "5934  0.879841  \n",
       "5935  1.470525  \n",
       "5936  0.514911  \n",
       "5937  1.515825  \n",
       "5938  0.972468  \n",
       "5939  1.069763  \n",
       "5940  1.049182  \n",
       "5941 -0.022299  \n",
       "5942  1.192926  \n",
       "5943  1.381152  \n",
       "5944 -1.656335  \n",
       "5945  1.206601  \n",
       "5946  0.853487  \n",
       "\n",
       "[5947 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items_df = []\n",
    "for i in range(df.shape[0]):\n",
    "    users_items_df += df['state_history'][i] \n",
    "    \n",
    "users_items_df = pd.DataFrame(users_items_df,columns = ['user_id','item_id',\n",
    "                                                        'price','v1','v2','v3','v4','v5'])\n",
    "users_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the first two covariates variables are features about users \n",
    "# and the forth and fifth variable are features about items\n",
    "# The variable 5 depends on .....\n",
    "\n",
    "user_v1 = users_items_df['v1'].unique()\n",
    "user_v2 = users_items_df['v2'].unique()\n",
    "users_ids = users_items_df['user_id'].unique()\n",
    "users_content= pd.DataFrame({'user_id' : user_id,'v1':user_v1,'v2':user_v2 })\n",
    "\n",
    "item_v3 = users_items_df['v3'].unique()\n",
    "item_v4 = users_items_df['v4'].unique()\n",
    "item_id = users_items_df['item_id'].unique()\n",
    "items_content= pd.DataFrame({'item_id' : item_id,'v3':item_v3,'v4':item_v4 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = df[df[\"rewards_history\"] > 0].reset_index(drop=True)\n",
    "neg_data = df[df[\"rewards_history\"] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "      <th>state_history</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>647.932910</td>\n",
       "      <td>[[92, 0, 995.4367425100899, 0.8019868269580972...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>178.207535</td>\n",
       "      <td>[[94, 0, 995.4367425100899, 0.731733947245598,...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>193.390014</td>\n",
       "      <td>[[89, 0, 995.4367425100899, 0.7959678436502442...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>775.443156</td>\n",
       "      <td>[[35, 0, 995.4367425100899, 1.0641933697598667...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>647.932910</td>\n",
       "      <td>[[94, 0, 995.4367425100899, 0.731733947245598,...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_history  rewards_history  \\\n",
       "0               4       647.932910   \n",
       "1              23       178.207535   \n",
       "2              19       193.390014   \n",
       "3               6       775.443156   \n",
       "4               4       647.932910   \n",
       "\n",
       "                                       state_history  user_id  \n",
       "0  [[92, 0, 995.4367425100899, 0.8019868269580972...       92  \n",
       "1  [[94, 0, 995.4367425100899, 0.731733947245598,...       94  \n",
       "2  [[89, 0, 995.4367425100899, 0.7959678436502442...       89  \n",
       "3  [[35, 0, 995.4367425100899, 1.0641933697598667...       35  \n",
       "4  [[94, 0, 995.4367425100899, 0.731733947245598,...       94  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_data[\"user_id\"] = [pos_data[\"state_history\"][i][0][0] for i in range(pos_data.shape[0])]\n",
    "pos_data.head()## There are some users that have more than one positive item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "      <th>state_history</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[5, 0, 995.4367425100899, -0.0168718993729635...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[58, 0, 995.4367425100899, 1.5616172497663623...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[41, 0, 995.4367425100899, 0.9170586867255156...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[76, 0, 995.4367425100899, 0.3964318617363663...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[76, 0, 995.4367425100899, 0.3964318617363663...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_history  rewards_history  \\\n",
       "0              10              0.0   \n",
       "1              14              0.0   \n",
       "2               6              0.0   \n",
       "3               5              0.0   \n",
       "4              24              0.0   \n",
       "\n",
       "                                       state_history  user_id  \n",
       "0  [[5, 0, 995.4367425100899, -0.0168718993729635...        5  \n",
       "1  [[58, 0, 995.4367425100899, 1.5616172497663623...       58  \n",
       "2  [[41, 0, 995.4367425100899, 0.9170586867255156...       41  \n",
       "3  [[76, 0, 995.4367425100899, 0.3964318617363663...       76  \n",
       "4  [[76, 0, 995.4367425100899, 0.3964318617363663...       76  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_data[\"user_id\"] = [neg_data[\"state_history\"][i][0][0] for i in range(neg_data.shape[0])]\n",
    "neg_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"Ignore y_true and return the mean of y_pred\n",
    "    \n",
    "    This is a hack to work-around the design of the Keras API that is\n",
    "    not really suited to train networks with a triplet loss by default.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(y_pred + 0 * y_true)\n",
    "\n",
    "\n",
    "def margin_comparator_loss(inputs, margin=1.):\n",
    "    \"\"\"Comparator loss for a pair of precomputed similarities\n",
    "    \n",
    "    If the inputs are cosine similarities, they each have range in\n",
    "    (-1, 1), therefore their difference have range in (-2, 2). Using\n",
    "    a margin of 1. can therefore make sense.\n",
    "\n",
    "    If the input similarities are not normalized, it can be beneficial\n",
    "    to use larger values for the margin of the comparator loss.\n",
    "    \"\"\"\n",
    "    positive_pair_sim, negative_pair_sim = inputs\n",
    "    return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, Dense\n",
    "from keras.layers import Lambda, Dot\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import dot, concatenate\n",
    "\n",
    "\n",
    "def build_models(n_users, n_items, latent_dim=64, l2_reg=0):\n",
    "    \"\"\"Build a triplet model and its companion similarity model\n",
    "    \n",
    "    The triplet model is used to train the weights of the companion\n",
    "    similarity model. The triplet model takes 1 user, 1 positive item\n",
    "    (relative to the selected user) and one negative item and is\n",
    "    trained with comparator loss.\n",
    "    \n",
    "    The similarity model takes one user and one item as input and return\n",
    "    compatibility score (aka the match score).\n",
    "    \"\"\"\n",
    "    # Common architectural components for the two models:\n",
    "    # - symbolic input placeholders\n",
    "    user_input = Input((1,), name='user_input')\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "\n",
    "    # - embeddings\n",
    "    l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "    user_layer = Embedding(input_dim=n_users, output_dim=latent_dim, input_length=1,\n",
    "                           name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "    \n",
    "    # The following embedding parameters will be shared to encode both\n",
    "    # the positive and negative items.\n",
    "    item_layer = Embedding(input_dim=n_items, output_dim=latent_dim, input_length=1,\n",
    "                           name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "    user_embedding = Flatten()(user_layer(user_input))\n",
    "    positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "    # - similarity computation between embeddings\n",
    "    positive_similarity = Dot(name=\"positive_similarity\",\n",
    "                              axes=1, normalize=True)(\n",
    "        [user_embedding, positive_item_embedding])\n",
    "    negative_similarity = Dot(name=\"negative_similarity\",\n",
    "                              axes=1, normalize=True)(\n",
    "        [user_embedding, negative_item_embedding])\n",
    "\n",
    "    # The triplet network model, only used for training\n",
    "    triplet_loss = Lambda(margin_comparator_loss,\n",
    "                          name='comparator_loss',\n",
    "                          output_shape=(1,))([positive_similarity, negative_similarity])\n",
    "\n",
    "    triplet_model = Model(inputs=[user_input,\n",
    "                                  positive_item_input,\n",
    "                                  negative_item_input],\n",
    "                          outputs=triplet_loss)\n",
    "    \n",
    "    # The match-score model, only use at inference to rank items for a given\n",
    "    # model: the model weights are shared with the triplet_model therefore\n",
    "    # we do not need to train it and therefore we do not need to plug a loss\n",
    "    # and an optimizer.\n",
    "    match_model = Model(inputs=[user_input, positive_item_input],\n",
    "                        outputs=positive_similarity)\n",
    "    \n",
    "    return triplet_model, match_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model, match_model = build_models(nb_users, nb_items, latent_dim = 16,l2_reg = 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triplets(pos_data,max_items):\n",
    "    \"\"\"\n",
    "    Sample negatives at random\n",
    "    \n",
    "    \"\"\"\n",
    "    range_itens = np.arange(max_items)\n",
    "    user_ids = pos_data['user_id'].values\n",
    "    pos_item_ids = pos_data['action_history'].values\n",
    "    \n",
    "    \n",
    "    user_pos_items = pos_data.groupby('user_id')['action_history'].apply(list)\n",
    "    neg_item_ids = np.array([])\n",
    "    for i in user_ids:\n",
    "        if i in set(user_pos_items.index):\n",
    "            number = np.random.choice([i for i in range_itens \n",
    "                                       if not i in user_pos_items[user_pos_items.index == i]])\n",
    "        else:\n",
    "            number = np.random.choice(range_itens,1)\n",
    "        neg_item_ids = np.append(neg_item_ids,number)\n",
    "    \n",
    "  \n",
    "    return [user_ids, pos_item_ids, neg_item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 6ms/step - loss: 1.0482\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 0.8868\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 0.8493\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 0.8529\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 0.7976\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 0.6929\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 0.7251\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 0.5833\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 101us/step - loss: 0.6203\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 0.5403\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 0.5743\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 0.5172\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 111us/step - loss: 0.4793\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 0.4286\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 0.4036\n",
      "2\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 0.3638\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 0.3716\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 206us/step - loss: 0.3797\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 0.3626\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 0.3763\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 0.3255\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 0.3237\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 0.3392\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 0.2783\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 0.2521\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 0.2976\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 0.3172\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 0.2712\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 0.2114\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 101us/step - loss: 0.2479\n",
      "7\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 0.2059\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 0.2586\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 0.2326\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 0.1982\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 0.2211\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 0.2396\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 0.1535\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 115us/step - loss: 0.1752\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 171us/step - loss: 0.1783\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 0.1908\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 0.2170\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 111us/step - loss: 0.1978\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 0.1667\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 0.1089\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 0.2001\n",
      "14\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 0.1799\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 0.1845\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 0.1360\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 0.1646\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 129us/step - loss: 0.1522\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 0.2109\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 0.1753\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 0.1155\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 0.1496\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 0.0939\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 0.1319\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 0.1510\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 122us/step - loss: 0.1345\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 0.1294\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 0.1495\n",
      "24\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 0.1303\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 0.1171\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 164us/step - loss: 0.1089\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 0.1811\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 112us/step - loss: 0.1919\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 0.0980\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 0.1188\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 0.1164\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 116us/step - loss: 0.1393\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 0.0800\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 0.1221\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 0.1391\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 0.1255\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 0.1336\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 109us/step - loss: 0.1145\n",
      "9\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 96us/step - loss: 0.1367\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 110us/step - loss: 0.1478\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 0.0794\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 96us/step - loss: 0.1528\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 93us/step - loss: 0.1038\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 97us/step - loss: 0.1273\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 90us/step - loss: 0.1410\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 98us/step - loss: 0.1163\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 97us/step - loss: 0.1672\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 92us/step - loss: 0.1177\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 0.1311\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 233us/step - loss: 0.1089\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 97us/step - loss: 0.1317\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 108us/step - loss: 0.1240\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 93us/step - loss: 0.0690\n",
      "13\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 86us/step - loss: 0.1335\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 113us/step - loss: 0.1191\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 88us/step - loss: 0.1563\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 150us/step - loss: 0.1490\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 81us/step - loss: 0.1117\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 100us/step - loss: 0.1509\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 84us/step - loss: 0.1007\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 119us/step - loss: 0.0944\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 100us/step - loss: 0.1078\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 115us/step - loss: 0.0874\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 201us/step - loss: 0.1535\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 91us/step - loss: 0.1475\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 112us/step - loss: 0.0564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 0.0681\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 105us/step - loss: 0.1387\n",
      "15\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 97us/step - loss: 0.0630\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 134us/step - loss: 0.1155\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 83us/step - loss: 0.1215\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 88us/step - loss: 0.1311\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 92us/step - loss: 0.0522\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 89us/step - loss: 0.1062\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 267us/step - loss: 0.0896\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 130us/step - loss: 0.1498\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 118us/step - loss: 0.1290\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 104us/step - loss: 0.0697\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 117us/step - loss: 0.1383\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 106us/step - loss: 0.0930\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 126us/step - loss: 0.0444\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 108us/step - loss: 0.0954\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 86us/step - loss: 0.0936\n",
      "26\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 98us/step - loss: 0.0639\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 89us/step - loss: 0.1059\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 95us/step - loss: 0.0775\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 91us/step - loss: 0.0794\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 89us/step - loss: 0.0494\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 104us/step - loss: 0.0549\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 86us/step - loss: 0.0691\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 121us/step - loss: 0.0740\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 119us/step - loss: 0.0954\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 111us/step - loss: 0.0770\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 182us/step - loss: 0.0820\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 100us/step - loss: 0.1194\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 87us/step - loss: 0.0921\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 109us/step - loss: 0.1355\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 86us/step - loss: 0.0893\n",
      "24\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 100us/step - loss: 0.0736\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 115us/step - loss: 0.1368\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 108us/step - loss: 0.0856\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 104us/step - loss: 0.0784\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 86us/step - loss: 0.0988\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 109us/step - loss: 0.0501\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 102us/step - loss: 0.1034\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 110us/step - loss: 0.0677\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 109us/step - loss: 0.0995\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 107us/step - loss: 0.1151\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 89us/step - loss: 0.0580\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 95us/step - loss: 0.1086\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 97us/step - loss: 0.1534\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 87us/step - loss: 0.0834\n",
      "Epoch 1/1\n",
      "69/69 [==============================] - 0s 120us/step - loss: 0.0633\n",
      "17\n",
      "Total reward for each epoch : 110.74262468210163\n"
     ]
    }
   ],
   "source": [
    "# we plug the identity loss and the a fake target variable ignored by\n",
    "# the model to be able to use the Keras API to train the triplet model\n",
    "triplet_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "fake_y = np.ones_like(pos_data['user_id'])\n",
    "params = {'user_id' : USER_ID}\n",
    "n_epochs = 15\n",
    "total_reward = 0\n",
    "\n",
    "generations = 10\n",
    "positive_data = pos_data\n",
    "\n",
    "for j in range(generations):\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        triplet_inputs = sample_triplets(positive_data,max_items = nb_items)\n",
    "\n",
    "        # Fit the model incrementally by doing a single pass over the\n",
    "        # sampled triplets.\n",
    "        triplet_model.fit(triplet_inputs, fake_y, shuffle=True,epochs=1)\n",
    "    \n",
    "    items_ids = np.array([next_state[i][1] for i in range(len(next_state))])\n",
    "    repeated_user_id  = np.empty_like(items_ids)\n",
    "    repeated_user_id.fill(next_state[0][0])\n",
    "    \n",
    "    predicted = match_model.predict([repeated_user_id,items_ids])\n",
    "    \n",
    "    predicted_item = np.argmax(predicted)\n",
    "    params['recommended_item'] = predicted_item\n",
    "    \n",
    "    r = requests.get(url = url_predict, params=params).json()\n",
    "    reward = r['reward']\n",
    "    total_reward += reward\n",
    "    \n",
    "    if(reward > 0):\n",
    "        positive_data = positive_data.append({'action_history':predicted_item,\n",
    "                                              'state_history':next_state,\n",
    "                                              'user_id':next_state[0][0]},\n",
    "                                               ignore_index=True)\n",
    "        \n",
    "    fake_y = np.ones_like(positive_data['user_id'])\n",
    "    next_state = r['state']\n",
    "\n",
    "print(\"Total reward for each epoch :\",total_reward/generations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, Dense, Dropout\n",
    "from keras.layers import Concatenate, Lambda\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def make_interaction_mlp(input_dim, n_hidden=1, hidden_size=64,\n",
    "                         dropout=0, l2_reg=None):\n",
    "    \"\"\"\n",
    "    Build the shared multi layer perceptron\n",
    "    \n",
    "    \"\"\"\n",
    "    mlp = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        # Plug the output unit directly: this is a simple\n",
    "        # linear regression model. Not dropout required.\n",
    "        mlp.add(Dense(1, input_dim=input_dim,\n",
    "                      activation='relu', kernel_regularizer=l2_reg))\n",
    "    else:\n",
    "        mlp.add(Dense(hidden_size, input_dim=input_dim,\n",
    "                      activation='relu', kernel_regularizer=l2_reg))\n",
    "        mlp.add(Dropout(dropout))\n",
    "        for i in range(n_hidden - 1):\n",
    "            mlp.add(Dense(hidden_size, activation='relu',\n",
    "                          kernel_regularizer=l2_reg))\n",
    "            mlp.add(Dropout(dropout))\n",
    "        mlp.add(Dense(1, activation='relu', kernel_regularizer=l2_reg))\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def build_models(n_users, n_items, user_dim=32, item_dim=64,\n",
    "                 n_hidden=1, hidden_size=64, dropout=0, l2_reg=0):\n",
    "    \"\"\"\n",
    "    Build models to train a deep triplet network\n",
    "    \n",
    "    \"\"\"\n",
    "    user_input = Input((1,), name='user_input')\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "    positive_meta_input = Input((2,), name='positive_meta_input')\n",
    "    negative_meta_input = Input((2,), name='negative_meta_input')\n",
    "\n",
    "    l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "    user_layer = Embedding(n_users, user_dim, input_length=1,\n",
    "                           name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "\n",
    "    # The following embedding parameters will be shared to encode both\n",
    "    # the positive and negative items.\n",
    "    item_layer = Embedding(n_items, item_dim, input_length=1,\n",
    "                           name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "    user_embedding = Flatten()(user_layer(user_input))\n",
    "    positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "\n",
    "    # Similarity computation between embeddings using a MLP similarity\n",
    "    positive_embeddings_pair = Concatenate(name=\"positive_embeddings_pair\")(\n",
    "        [user_embedding, positive_item_embedding,positive_meta_input])\n",
    "    positive_embeddings_pair = Dropout(dropout)(positive_embeddings_pair)\n",
    "    \n",
    "    negative_embeddings_pair = Concatenate(name=\"negative_embeddings_pair\")(\n",
    "        [user_embedding, negative_item_embedding,negative_meta_input])\n",
    "    negative_embeddings_pair = Dropout(dropout)(negative_embeddings_pair)\n",
    "\n",
    "    # Instanciate the shared similarity architecture\n",
    "    interaction_layers = make_interaction_mlp(\n",
    "        user_dim + item_dim + 2, n_hidden=n_hidden, hidden_size=hidden_size,\n",
    "        dropout=dropout, l2_reg=l2_reg)\n",
    "\n",
    "    positive_similarity = interaction_layers(positive_embeddings_pair)\n",
    "    negative_similarity = interaction_layers(negative_embeddings_pair)\n",
    "\n",
    "    # The triplet network model, only used for training\n",
    "    triplet_loss = Lambda(margin_comparator_loss, output_shape=(1,),\n",
    "                          name='comparator_loss')(\n",
    "        [positive_similarity, negative_similarity])\n",
    "\n",
    "    deep_triplet_model = Model(inputs=[user_input,\n",
    "                                       positive_item_input,\n",
    "                                       negative_item_input,\n",
    "                                       positive_meta_input,\n",
    "                                       negative_meta_input\n",
    "                                      ],\n",
    "                               outputs=[triplet_loss])\n",
    "\n",
    "    # The match-score model, only used at inference\n",
    "    deep_match_model = Model(inputs=[user_input, positive_item_input,positive_meta_input],\n",
    "                             outputs=[positive_similarity])\n",
    "\n",
    "    return deep_match_model, deep_triplet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = dict(\n",
    "    user_dim=50,\n",
    "    item_dim=16,\n",
    "    n_hidden=1,\n",
    "    hidden_size=16,\n",
    "    dropout=0.2,\n",
    "    l2_reg=1\n",
    ")\n",
    "deep_match_model, deep_triplet_model = build_models(nb_users, nb_items,\n",
    "                                                    **hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triplets(pos_data,items_content,max_items):\n",
    "    \"\"\"\n",
    "    Sample the data and put in the format \n",
    "    [user_ids, pos_item_ids, neg_item_ids,pos_item_metadata,neg_item_metadata]\n",
    "    \n",
    "    \"\"\"\n",
    "    range_itens = np.arange(max_items)\n",
    "    user_ids = pos_data['user_id'].values\n",
    "    pos_item_ids = pos_data['action_history'].values\n",
    "    \n",
    "    pos_item_metadata = items_content.loc[pos_item_ids][['v3','v4']].values\n",
    "    \n",
    "    ##TODO\n",
    "    user_pos_items = pos_data.groupby('user_id')['action_history'].apply(list)\n",
    "    neg_item_ids = np.array([])\n",
    "    for i in user_ids:\n",
    "        if i in set(user_pos_items.index):\n",
    "            number = np.random.choice([i for i in range_itens \n",
    "                                       if not i in user_pos_items[user_pos_items.index == i]])\n",
    "        else:\n",
    "            number = np.random.choice(range_itens,1)\n",
    "        neg_item_ids = np.append(neg_item_ids,number)\n",
    "    \n",
    "    neg_item_metadata = items_content.loc[neg_item_ids][['v3','v4']].values\n",
    "    \n",
    "    \n",
    "    return [user_ids, pos_item_ids, neg_item_ids,pos_item_metadata,neg_item_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "67/67 [==============================] - 1s 16ms/step - loss: 33.0896\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 31.9975\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 30.9604\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 29.9301\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 28.9829\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 28.0754\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 27.2185\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 26.3803\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 25.6160\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 131us/step - loss: 24.8658\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 145us/step - loss: 24.1641\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 23.4919\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 154us/step - loss: 22.8559\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 22.2383\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 21.6862\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 21.1164\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 20.5894\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 20.0701\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 19.5974\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 19.1431\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 18.6805\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 136us/step - loss: 18.2439\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 17.8443\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 71us/step - loss: 17.4272\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 17.0487\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 16.6597\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 16.2947\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 15.9206\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 15.5765\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 136us/step - loss: 15.2447\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 14.9075\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 149us/step - loss: 14.5927\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 14.2781\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 13.9560\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 13.6506\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 13.3621\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 13.0833\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 12.7930\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 12.5057\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 12.2475\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 11.9831\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 11.7336\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 11.4798\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 11.2315\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 10.9902\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 10.7553\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 10.5276\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 10.3096\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 10.0873\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 9.8662\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 9.6572\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 9.4546\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 173us/step - loss: 9.2543\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 179us/step - loss: 9.0560\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 8.8717\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 8.6777\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 8.5003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 8.3200\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 8.1495\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 7.9785\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 7.8122\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 115us/step - loss: 7.6498\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 7.4911\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 7.3347\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 7.1850\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 138us/step - loss: 7.0384\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 6.8937\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 118us/step - loss: 6.7509\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 160us/step - loss: 6.6136\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 6.4786\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 139us/step - loss: 6.3461\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 6.2215\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 6.0973\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 5.9724\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 71us/step - loss: 5.8534\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 133us/step - loss: 5.7348\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 1ms/step - loss: 5.6214\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 5.5111\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 5.4010\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 5.2946\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 5.1919\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 5.0916\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 4.9921\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 4.8958\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 4.8011\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 111us/step - loss: 4.7101\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 4.6208\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 4.5329\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 4.4475\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 4.3644\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 4.2830\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 4.2038\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 247us/step - loss: 4.1264\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 4.0511\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 3.9770\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 3.9054\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 3.8350\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 3.7671\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 3.7004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 3.6354\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 3.5720\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 3.5101\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 101us/step - loss: 3.4498\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 3.3910\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 3.3336\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 3.2775\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 3.2229\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 3.1696\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 3.1177\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 186us/step - loss: 3.0670\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 3.0176\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 2.9694\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 2.9225\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 118us/step - loss: 2.8767\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 2.8321\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 2.7886\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 2.7461\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 122us/step - loss: 2.7048\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 2.6645\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 112us/step - loss: 2.6252\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 121us/step - loss: 2.5868\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 2.5494\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 158us/step - loss: 2.5130\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 146us/step - loss: 2.4775\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 153us/step - loss: 2.4429\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 2.4091\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 123us/step - loss: 2.3762\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 2.3442\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 2.3130\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 2.2825\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 2.2528\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 277us/step - loss: 2.2239\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 2.1957\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 157us/step - loss: 2.1682\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 2.1414\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 156us/step - loss: 2.1153\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 2.0899\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 2.0650\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 2.0409\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 2.0173\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 1.9944\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 124us/step - loss: 1.9720\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.9502\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.9289\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.9082\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.8880\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 122us/step - loss: 1.8683\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 147us/step - loss: 1.8491\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 138us/step - loss: 1.8304\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.8122\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 1.7944\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.7771\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 137us/step - loss: 1.7602\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 157us/step - loss: 1.7437\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.7277\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 1.7120\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 129us/step - loss: 1.6968\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.6819\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 143us/step - loss: 1.6674\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.6532\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.6394\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 1.6260\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.6129\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 1.6001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.5876\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.5755\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.5636\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.5520\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 1.5408\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 118us/step - loss: 1.5297\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 120us/step - loss: 1.5190\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 133us/step - loss: 1.5085\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.4983\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 118us/step - loss: 1.4883\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 131us/step - loss: 1.4786\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 133us/step - loss: 1.4691\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.4598\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.4508\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 1.4419\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 135us/step - loss: 1.4333\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 1.4249\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 123us/step - loss: 1.4167\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.4087\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.4008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 129us/step - loss: 1.3932\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.3857\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 1.3784\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 167us/step - loss: 1.3713\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.3643\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.3575\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 131us/step - loss: 1.3509\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.3444\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.3380\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 130us/step - loss: 1.3318\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.3257\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 147us/step - loss: 1.3198\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.3140\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.3084\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 130us/step - loss: 1.3028\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.2974\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 138us/step - loss: 1.2921\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.2869\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.2819\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 130us/step - loss: 1.2769\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 139us/step - loss: 1.2721\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 74us/step - loss: 1.2673\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.2627\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.2581\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 137us/step - loss: 1.2537\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.2493\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.2451\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.2409\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 176us/step - loss: 1.2368\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 127us/step - loss: 1.2328\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.2289\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 1.2250\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.2213\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 109us/step - loss: 1.2176\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 1.2140\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 1.2104\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.2070\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.2036\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.2002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 125us/step - loss: 1.1970\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 145us/step - loss: 1.1938\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 118us/step - loss: 1.1906\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 1.1875\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 1.1845\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 146us/step - loss: 1.1815\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 164us/step - loss: 1.1786\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 138us/step - loss: 1.1758\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.1730\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 113us/step - loss: 1.1702\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 124us/step - loss: 1.1675\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.1649\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.1623\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 153us/step - loss: 1.1597\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.1572\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 1.1547\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.1523\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 165us/step - loss: 1.1499\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 112us/step - loss: 1.1476\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 129us/step - loss: 1.1453\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.1430\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 146us/step - loss: 1.1408\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 158us/step - loss: 1.1387\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 149us/step - loss: 1.1365\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 123us/step - loss: 1.1344\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.1324\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.1303\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.1283\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 112us/step - loss: 1.1264\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.1244\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.1225\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 127us/step - loss: 1.1207\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.1188\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 189us/step - loss: 1.1170\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.1152\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 309us/step - loss: 1.1135\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 125us/step - loss: 1.1118\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.1101\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.1084\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.1068\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 1.1052\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.1036\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.1020\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.1005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0990\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0975\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0960\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0946\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0932\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0918\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0904\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0890\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 1.0877\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 162us/step - loss: 1.0864\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 211us/step - loss: 1.0851\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0838\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 1.0825\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 134us/step - loss: 1.0813\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0801\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0789\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0777\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0765\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0754\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0743\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0731\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0720\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0710\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0699\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0688\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0678\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0668\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0658\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0648\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0638\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0629\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0619\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0610\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0601\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0591\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0583\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0574\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0565\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0556\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0548\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0540\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 79us/step - loss: 1.0532\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0523\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0515\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0508\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0500\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0492\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0485\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0477\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 101us/step - loss: 1.0470\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0463\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0456\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0449\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0442\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0435\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0428\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0422\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 1.0415\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0409\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0403\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0396\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0390\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0384\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0378\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 72us/step - loss: 1.0372\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0366\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0361\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0355\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 1.0350\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 1.0344\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0339\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0333\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0328\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0323\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0318\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 1.0313\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0308\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0303\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0298\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.0294\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0289\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 1.0284\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0280\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.0275\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0271\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0267\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 137us/step - loss: 1.0262\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0258\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0254\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0250\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 71us/step - loss: 1.0246\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0242\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0238\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0234\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0230\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0227\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 101us/step - loss: 1.0223\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0219\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 111us/step - loss: 1.0216\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0212\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 120us/step - loss: 1.0209\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0205\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0202\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0199\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0195\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0192\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0189\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0186\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0183\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0180\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0177\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0174\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0171\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 72us/step - loss: 1.0168\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0165\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0163\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0160\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0157\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0155\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0152\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0149\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0147\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0144\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0142\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.0140\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0137\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0135\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0133\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0130\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0128\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0126\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0124\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0122\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0120\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0118\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 1.0116\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0114\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0112\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0110\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0108\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0106\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0104\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0102\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0100\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 77us/step - loss: 1.0099\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0097\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0095\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 72us/step - loss: 1.0094\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0092\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0090\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0089\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0087\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0086\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0084\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0083\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0081\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0080\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0078\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0077\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 1.0076\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0074\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0073\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0072\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0070\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 121us/step - loss: 1.0069\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0068\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0067\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0065\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0064\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0063\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0062\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0061\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0060\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0059\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 1.0058\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0056\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 1.0055\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0054\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0053\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0052\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0051\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0051\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 1.0050\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 68us/step - loss: 1.0049\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 129us/step - loss: 1.0048\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0047\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0046\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0045\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0044\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0044\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0043\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0042\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0041\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0040\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0040\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 1.0039\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0038\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.0037\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0037\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0036\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0035\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0035\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0034\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.0033\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0033\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0032\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0031\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0031\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0030\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 1.0030\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0029\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0029\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 127us/step - loss: 1.0028\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0027\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 1.0027\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0026\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0026\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0025\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0025\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0024\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0024\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 1.0023\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0023\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0023\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0022\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0022\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0021\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0021\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0020\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0020\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0020\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 72us/step - loss: 1.0019\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.0019\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0018\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0018\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0018\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0017\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0017\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0017\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0016\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0016\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0016\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0015\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0015\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0015\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0014\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 107us/step - loss: 1.0014\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 85us/step - loss: 1.0014\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0014\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0013\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0013\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0013\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0013\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 192us/step - loss: 1.0012\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0012\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0012\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0012\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0011\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0011\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0011\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0011\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0010\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0010\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0010\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0010\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0010\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0009\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0009\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0009\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 1.0009\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 72us/step - loss: 1.0009\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0008\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 1.0007\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0007\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0007\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0007\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0007\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0007\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0006\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0005\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0004\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 105us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 138us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 191us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 220us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 1.0003\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 215us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 236us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 115us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 222us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 125us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 135us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 111us/step - loss: 1.0002\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 142us/step - loss: 1.0001\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 81us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 198us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 187us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 113us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 135us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 135us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 134us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 109us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 223us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 151us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 925us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 285us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 138us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 206us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 131us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0001\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 199us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 136us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 128us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 198us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 167us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 178us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 276us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 152us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 178us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 145us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 111us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 129us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 173us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 164us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 116us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 183us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 193us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 167us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 161us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 130us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 114us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 123us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 133us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 137us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 181us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 104us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 125us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 119us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 144us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 141us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 139us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 172us/step - loss: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 128us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 155us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 131us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 123us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 137us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 128us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 136us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 141us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 126us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 172us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 127us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 131us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 137us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 153us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 116us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 128us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 157us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 229us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 179us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 87us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 106us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 73us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 108us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 197us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 71us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 99us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 93us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 90us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 98us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 155us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 120us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 117us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 92us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 96us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 110us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 103us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 97us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 126us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 100us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 94us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 89us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 102us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "67/67 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 142us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 98us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 99us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 142us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 110us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 97us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 177us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 115us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 73us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 168us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 386us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 146us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 129us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 72us/step - loss: 1.0000\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 113us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 91us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 85us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 98us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 93us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 129us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 75us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 102us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 97us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 87us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 72us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 83us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 71us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 110us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 100us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 78us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 92us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 72us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 89us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 82us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 88us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 98us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 77us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 86us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 130us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 95us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 109us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 74us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 170us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 90us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 80us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 126us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 111us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 73us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 76us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 92us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 84us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 92us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 90us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 81us/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "68/68 [==============================] - 0s 79us/step - loss: 1.0000\n",
      "Total reward for each epoch : 99.54367425100898\n"
     ]
    }
   ],
   "source": [
    "# we plug the identity loss and the a fake target variable ignored by\n",
    "# the model to be able to use the Keras API to train the triplet model\n",
    "deep_triplet_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "fake_y = np.ones_like(pos_data['user_id'])\n",
    "params = {'user_id' : USER_ID}\n",
    "n_epochs = 100\n",
    "total_reward = 0\n",
    "generations = 10\n",
    "\n",
    "positive_data = pos_data\n",
    "\n",
    "for j in range(generations):\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        triplet_inputs = sample_triplets(positive_data,items_content,max_items = nb_items)\n",
    "\n",
    "        # Fit the model incrementally by doing a single pass over the\n",
    "        # sampled triplets.\n",
    "        deep_triplet_model.fit(triplet_inputs, fake_y, shuffle=True,\n",
    "                          batch_size=64, epochs=1)\n",
    "    \n",
    "    # Predicting \n",
    "    items_ids = np.array([next_state[i][1] for i in range(len(next_state))])\n",
    "    repeated_user_id  = np.empty_like(items_ids)\n",
    "    repeated_user_id.fill(next_state[0][0])\n",
    "    \n",
    "    pos_metadata = items_content.loc[items_ids][['v3','v4']].values\n",
    "\n",
    "    predicted = deep_match_model.predict([repeated_user_id,items_ids,pos_metadata])\n",
    "    \n",
    "    predicted_item = np.argmax(predicted)\n",
    "    params['recommended_item'] = predicted_item\n",
    "    \n",
    "    r = requests.get(url=url_predict, params=params).json()\n",
    "    reward = r['reward']\n",
    "    total_reward += reward\n",
    "    \n",
    "    if(reward > 0):\n",
    "        positive_data = positive_data.append({'action_history':predicted_item,\n",
    "                                              'state_history':next_state,\n",
    "                                              'user_id':next_state[0][0]},\n",
    "                                               ignore_index=True)\n",
    "    \n",
    "    fake_y = np.ones_like(positive_data['user_id'])\n",
    "    next_state = r['state']\n",
    "\n",
    "print(\"Total reward for each epoch :\",total_reward/generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
