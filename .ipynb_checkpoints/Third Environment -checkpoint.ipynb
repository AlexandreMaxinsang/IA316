{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dropout, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third environmement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['action_history', 'nb_items', 'nb_users', 'next_state', 'rewards_history', 'state_history'])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attributes fa\n",
    "USER_ID = 'IAHIZPIW80WPGDW7P7JE'\n",
    "BASE_URL = \"http://35.180.178.243\"\n",
    "url_reset = BASE_URL + \"/reset\"\n",
    "url_predict = BASE_URL + \"/predict\"\n",
    "params = {\"user_id\" : USER_ID}\n",
    "\n",
    "def load_data(url_reset,params) :\n",
    "    r = requests.get(url=url_reset, params=params)\n",
    "    data = r.json()\n",
    "    return data\n",
    "\n",
    "data = load_data(url_reset,params)\n",
    "nb_users = data[\"nb_users\"]\n",
    "nb_items = data[\"nb_items\"]\n",
    "next_state = data[\"next_state\"]\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "      <th>state_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>42.678405</td>\n",
       "      <td>[[32, 0, 561.9608319155392, 2.7606149744183837...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>342.929576</td>\n",
       "      <td>[[57, 0, 561.9608319155392, 0.3076770015376174...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[38, 0, 561.9608319155392, 1.7039990882609266...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[79, 0, 561.9608319155392, -0.679139726452107...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[50, 0, 561.9608319155392, 1.3492680753336916...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_history  rewards_history  \\\n",
       "0              13        42.678405   \n",
       "1              18       342.929576   \n",
       "2              15         0.000000   \n",
       "3              23         0.000000   \n",
       "4               6         0.000000   \n",
       "\n",
       "                                       state_history  \n",
       "0  [[32, 0, 561.9608319155392, 2.7606149744183837...  \n",
       "1  [[57, 0, 561.9608319155392, 0.3076770015376174...  \n",
       "2  [[38, 0, 561.9608319155392, 1.7039990882609266...  \n",
       "3  [[79, 0, 561.9608319155392, -0.679139726452107...  \n",
       "4  [[50, 0, 561.9608319155392, 1.3492680753336916...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blacklisted_set = set((\"next_state\",\"nb_items\",\"nb_users\"))\n",
    "new_dict = {key : value for key, value in data.items() if key not in blacklisted_set}\n",
    "\n",
    "df = pd.DataFrame(new_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.240000</td>\n",
       "      <td>129.973246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.742112</td>\n",
       "      <td>248.991807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>152.174722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>963.357634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       action_history  rewards_history\n",
       "count      200.000000       200.000000\n",
       "mean        14.240000       129.973246\n",
       "std          8.742112       248.991807\n",
       "min          0.000000         0.000000\n",
       "25%          7.000000         0.000000\n",
       "50%         14.000000         0.000000\n",
       "75%         22.000000       152.174722\n",
       "max         29.000000       963.357634"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action_history     140\n",
       "rewards_history    140\n",
       "state_history      140\n",
       "dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rewards_history']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>price</th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>v3</th>\n",
       "      <th>v4</th>\n",
       "      <th>v5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>561.960832</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>-0.398634</td>\n",
       "      <td>2.223695</td>\n",
       "      <td>0.835217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>237.133114</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>2.323786</td>\n",
       "      <td>2.157464</td>\n",
       "      <td>3.102571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>825.248994</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>2.338465</td>\n",
       "      <td>0.426121</td>\n",
       "      <td>1.230357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>963.357634</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.482943</td>\n",
       "      <td>1.885303</td>\n",
       "      <td>-0.710399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>478.175399</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.779073</td>\n",
       "      <td>0.683714</td>\n",
       "      <td>-0.372410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>571.098599</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>0.750748</td>\n",
       "      <td>3.071613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>182.731294</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.212972</td>\n",
       "      <td>-0.522265</td>\n",
       "      <td>0.400256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>473.395808</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.589554</td>\n",
       "      <td>0.882864</td>\n",
       "      <td>1.326484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>141.989198</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.884052</td>\n",
       "      <td>1.993851</td>\n",
       "      <td>0.674759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>720.382024</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.312128</td>\n",
       "      <td>1.090891</td>\n",
       "      <td>1.812324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>190.312965</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>-0.753710</td>\n",
       "      <td>0.727559</td>\n",
       "      <td>1.488110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32</td>\n",
       "      <td>11</td>\n",
       "      <td>258.921386</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.085627</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>0.890435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>848.365642</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.789960</td>\n",
       "      <td>1.363544</td>\n",
       "      <td>1.072653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>42.678405</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.088100</td>\n",
       "      <td>2.158506</td>\n",
       "      <td>2.021524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>32</td>\n",
       "      <td>14</td>\n",
       "      <td>183.878299</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>2.761234</td>\n",
       "      <td>2.388465</td>\n",
       "      <td>1.097239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32</td>\n",
       "      <td>15</td>\n",
       "      <td>979.434841</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>2.176301</td>\n",
       "      <td>1.311962</td>\n",
       "      <td>0.238648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>601.232239</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.791140</td>\n",
       "      <td>1.020159</td>\n",
       "      <td>2.087004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>796.257804</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.213049</td>\n",
       "      <td>-0.661361</td>\n",
       "      <td>1.670272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>342.929576</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.398428</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>-0.107450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>844.419744</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.394209</td>\n",
       "      <td>0.159648</td>\n",
       "      <td>2.160344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>32</td>\n",
       "      <td>20</td>\n",
       "      <td>354.364725</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>2.002790</td>\n",
       "      <td>0.236735</td>\n",
       "      <td>1.679352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>51.115609</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.946232</td>\n",
       "      <td>2.405041</td>\n",
       "      <td>-0.188037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>32</td>\n",
       "      <td>22</td>\n",
       "      <td>887.345972</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.829769</td>\n",
       "      <td>0.640853</td>\n",
       "      <td>2.741462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>32</td>\n",
       "      <td>23</td>\n",
       "      <td>715.127025</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.093387</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>0.569086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>665.719121</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>2.221688</td>\n",
       "      <td>2.014475</td>\n",
       "      <td>-0.122890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>32</td>\n",
       "      <td>25</td>\n",
       "      <td>610.122703</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.708089</td>\n",
       "      <td>1.270556</td>\n",
       "      <td>0.831218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>868.164644</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.090908</td>\n",
       "      <td>0.573644</td>\n",
       "      <td>2.831675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>32</td>\n",
       "      <td>27</td>\n",
       "      <td>416.251293</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>1.471981</td>\n",
       "      <td>2.474257</td>\n",
       "      <td>1.138897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>360.403294</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>-0.247238</td>\n",
       "      <td>0.663706</td>\n",
       "      <td>2.171907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>453.888864</td>\n",
       "      <td>2.760615</td>\n",
       "      <td>1.314982</td>\n",
       "      <td>0.973458</td>\n",
       "      <td>1.091296</td>\n",
       "      <td>1.863229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>561.960832</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>-0.398634</td>\n",
       "      <td>2.223695</td>\n",
       "      <td>0.958894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>237.133114</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>2.323786</td>\n",
       "      <td>2.157464</td>\n",
       "      <td>1.106860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>825.248994</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>2.338465</td>\n",
       "      <td>0.426121</td>\n",
       "      <td>1.543278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5917</th>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>963.357634</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.482943</td>\n",
       "      <td>1.885303</td>\n",
       "      <td>0.273067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5918</th>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>478.175399</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.779073</td>\n",
       "      <td>0.683714</td>\n",
       "      <td>1.483113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5919</th>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>571.098599</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.458886</td>\n",
       "      <td>0.750748</td>\n",
       "      <td>3.213251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>182.731294</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.212972</td>\n",
       "      <td>-0.522265</td>\n",
       "      <td>0.638253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5921</th>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>473.395808</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.589554</td>\n",
       "      <td>0.882864</td>\n",
       "      <td>0.614706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5922</th>\n",
       "      <td>64</td>\n",
       "      <td>8</td>\n",
       "      <td>141.989198</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.884052</td>\n",
       "      <td>1.993851</td>\n",
       "      <td>1.912616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5923</th>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>720.382024</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.312128</td>\n",
       "      <td>1.090891</td>\n",
       "      <td>-0.123466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5924</th>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>190.312965</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>-0.753710</td>\n",
       "      <td>0.727559</td>\n",
       "      <td>0.260533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5925</th>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>258.921386</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.085627</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>2.415365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5926</th>\n",
       "      <td>64</td>\n",
       "      <td>12</td>\n",
       "      <td>848.365642</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.789960</td>\n",
       "      <td>1.363544</td>\n",
       "      <td>1.982029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5927</th>\n",
       "      <td>64</td>\n",
       "      <td>13</td>\n",
       "      <td>42.678405</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.088100</td>\n",
       "      <td>2.158506</td>\n",
       "      <td>-0.304676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5928</th>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>183.878299</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>2.761234</td>\n",
       "      <td>2.388465</td>\n",
       "      <td>1.109033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5929</th>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>979.434841</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>2.176301</td>\n",
       "      <td>1.311962</td>\n",
       "      <td>1.906104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5930</th>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>601.232239</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.791140</td>\n",
       "      <td>1.020159</td>\n",
       "      <td>0.376991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5931</th>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>796.257804</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.213049</td>\n",
       "      <td>-0.661361</td>\n",
       "      <td>1.090698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5932</th>\n",
       "      <td>64</td>\n",
       "      <td>18</td>\n",
       "      <td>342.929576</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.398428</td>\n",
       "      <td>0.183075</td>\n",
       "      <td>2.018951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5933</th>\n",
       "      <td>64</td>\n",
       "      <td>19</td>\n",
       "      <td>844.419744</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.394209</td>\n",
       "      <td>0.159648</td>\n",
       "      <td>0.308224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5934</th>\n",
       "      <td>64</td>\n",
       "      <td>20</td>\n",
       "      <td>354.364725</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>2.002790</td>\n",
       "      <td>0.236735</td>\n",
       "      <td>-0.881957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5935</th>\n",
       "      <td>64</td>\n",
       "      <td>21</td>\n",
       "      <td>51.115609</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.946232</td>\n",
       "      <td>2.405041</td>\n",
       "      <td>1.179881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5936</th>\n",
       "      <td>64</td>\n",
       "      <td>22</td>\n",
       "      <td>887.345972</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.829769</td>\n",
       "      <td>0.640853</td>\n",
       "      <td>1.768965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5937</th>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>715.127025</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.093387</td>\n",
       "      <td>0.909566</td>\n",
       "      <td>2.555747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5938</th>\n",
       "      <td>64</td>\n",
       "      <td>24</td>\n",
       "      <td>665.719121</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>2.221688</td>\n",
       "      <td>2.014475</td>\n",
       "      <td>1.674830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5939</th>\n",
       "      <td>64</td>\n",
       "      <td>25</td>\n",
       "      <td>610.122703</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.708089</td>\n",
       "      <td>1.270556</td>\n",
       "      <td>1.242804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>64</td>\n",
       "      <td>26</td>\n",
       "      <td>868.164644</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.090908</td>\n",
       "      <td>0.573644</td>\n",
       "      <td>3.596345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5941</th>\n",
       "      <td>64</td>\n",
       "      <td>27</td>\n",
       "      <td>416.251293</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>1.471981</td>\n",
       "      <td>2.474257</td>\n",
       "      <td>-0.309062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5942</th>\n",
       "      <td>64</td>\n",
       "      <td>28</td>\n",
       "      <td>360.403294</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>-0.247238</td>\n",
       "      <td>0.663706</td>\n",
       "      <td>1.384349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5943</th>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>453.888864</td>\n",
       "      <td>0.281007</td>\n",
       "      <td>4.219850</td>\n",
       "      <td>0.973458</td>\n",
       "      <td>1.091296</td>\n",
       "      <td>-0.148031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5944 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id  item_id       price        v1        v2        v3        v4  \\\n",
       "0          32        0  561.960832  2.760615  1.314982 -0.398634  2.223695   \n",
       "1          32        1  237.133114  2.760615  1.314982  2.323786  2.157464   \n",
       "2          32        2  825.248994  2.760615  1.314982  2.338465  0.426121   \n",
       "3          32        3  963.357634  2.760615  1.314982  1.482943  1.885303   \n",
       "4          32        4  478.175399  2.760615  1.314982  0.779073  0.683714   \n",
       "5          32        5  571.098599  2.760615  1.314982  0.458886  0.750748   \n",
       "6          32        6  182.731294  2.760615  1.314982  1.212972 -0.522265   \n",
       "7          32        7  473.395808  2.760615  1.314982  0.589554  0.882864   \n",
       "8          32        8  141.989198  2.760615  1.314982  1.884052  1.993851   \n",
       "9          32        9  720.382024  2.760615  1.314982  1.312128  1.090891   \n",
       "10         32       10  190.312965  2.760615  1.314982 -0.753710  0.727559   \n",
       "11         32       11  258.921386  2.760615  1.314982  1.085627  0.270393   \n",
       "12         32       12  848.365642  2.760615  1.314982  0.789960  1.363544   \n",
       "13         32       13   42.678405  2.760615  1.314982  1.088100  2.158506   \n",
       "14         32       14  183.878299  2.760615  1.314982  2.761234  2.388465   \n",
       "15         32       15  979.434841  2.760615  1.314982  2.176301  1.311962   \n",
       "16         32       16  601.232239  2.760615  1.314982  1.791140  1.020159   \n",
       "17         32       17  796.257804  2.760615  1.314982  1.213049 -0.661361   \n",
       "18         32       18  342.929576  2.760615  1.314982  0.398428  0.183075   \n",
       "19         32       19  844.419744  2.760615  1.314982  1.394209  0.159648   \n",
       "20         32       20  354.364725  2.760615  1.314982  2.002790  0.236735   \n",
       "21         32       21   51.115609  2.760615  1.314982  1.946232  2.405041   \n",
       "22         32       22  887.345972  2.760615  1.314982  1.829769  0.640853   \n",
       "23         32       23  715.127025  2.760615  1.314982  1.093387  0.909566   \n",
       "24         32       24  665.719121  2.760615  1.314982  2.221688  2.014475   \n",
       "25         32       25  610.122703  2.760615  1.314982  0.708089  1.270556   \n",
       "26         32       26  868.164644  2.760615  1.314982  1.090908  0.573644   \n",
       "27         32       27  416.251293  2.760615  1.314982  1.471981  2.474257   \n",
       "28         32       28  360.403294  2.760615  1.314982 -0.247238  0.663706   \n",
       "29         32       29  453.888864  2.760615  1.314982  0.973458  1.091296   \n",
       "...       ...      ...         ...       ...       ...       ...       ...   \n",
       "5914       64        0  561.960832  0.281007  4.219850 -0.398634  2.223695   \n",
       "5915       64        1  237.133114  0.281007  4.219850  2.323786  2.157464   \n",
       "5916       64        2  825.248994  0.281007  4.219850  2.338465  0.426121   \n",
       "5917       64        3  963.357634  0.281007  4.219850  1.482943  1.885303   \n",
       "5918       64        4  478.175399  0.281007  4.219850  0.779073  0.683714   \n",
       "5919       64        5  571.098599  0.281007  4.219850  0.458886  0.750748   \n",
       "5920       64        6  182.731294  0.281007  4.219850  1.212972 -0.522265   \n",
       "5921       64        7  473.395808  0.281007  4.219850  0.589554  0.882864   \n",
       "5922       64        8  141.989198  0.281007  4.219850  1.884052  1.993851   \n",
       "5923       64        9  720.382024  0.281007  4.219850  1.312128  1.090891   \n",
       "5924       64       10  190.312965  0.281007  4.219850 -0.753710  0.727559   \n",
       "5925       64       11  258.921386  0.281007  4.219850  1.085627  0.270393   \n",
       "5926       64       12  848.365642  0.281007  4.219850  0.789960  1.363544   \n",
       "5927       64       13   42.678405  0.281007  4.219850  1.088100  2.158506   \n",
       "5928       64       14  183.878299  0.281007  4.219850  2.761234  2.388465   \n",
       "5929       64       15  979.434841  0.281007  4.219850  2.176301  1.311962   \n",
       "5930       64       16  601.232239  0.281007  4.219850  1.791140  1.020159   \n",
       "5931       64       17  796.257804  0.281007  4.219850  1.213049 -0.661361   \n",
       "5932       64       18  342.929576  0.281007  4.219850  0.398428  0.183075   \n",
       "5933       64       19  844.419744  0.281007  4.219850  1.394209  0.159648   \n",
       "5934       64       20  354.364725  0.281007  4.219850  2.002790  0.236735   \n",
       "5935       64       21   51.115609  0.281007  4.219850  1.946232  2.405041   \n",
       "5936       64       22  887.345972  0.281007  4.219850  1.829769  0.640853   \n",
       "5937       64       23  715.127025  0.281007  4.219850  1.093387  0.909566   \n",
       "5938       64       24  665.719121  0.281007  4.219850  2.221688  2.014475   \n",
       "5939       64       25  610.122703  0.281007  4.219850  0.708089  1.270556   \n",
       "5940       64       26  868.164644  0.281007  4.219850  1.090908  0.573644   \n",
       "5941       64       27  416.251293  0.281007  4.219850  1.471981  2.474257   \n",
       "5942       64       28  360.403294  0.281007  4.219850 -0.247238  0.663706   \n",
       "5943       64       29  453.888864  0.281007  4.219850  0.973458  1.091296   \n",
       "\n",
       "            v5  \n",
       "0     0.835217  \n",
       "1     3.102571  \n",
       "2     1.230357  \n",
       "3    -0.710399  \n",
       "4    -0.372410  \n",
       "5     3.071613  \n",
       "6     0.400256  \n",
       "7     1.326484  \n",
       "8     0.674759  \n",
       "9     1.812324  \n",
       "10    1.488110  \n",
       "11    0.890435  \n",
       "12    1.072653  \n",
       "13    2.021524  \n",
       "14    1.097239  \n",
       "15    0.238648  \n",
       "16    2.087004  \n",
       "17    1.670272  \n",
       "18   -0.107450  \n",
       "19    2.160344  \n",
       "20    1.679352  \n",
       "21   -0.188037  \n",
       "22    2.741462  \n",
       "23    0.569086  \n",
       "24   -0.122890  \n",
       "25    0.831218  \n",
       "26    2.831675  \n",
       "27    1.138897  \n",
       "28    2.171907  \n",
       "29    1.863229  \n",
       "...        ...  \n",
       "5914  0.958894  \n",
       "5915  1.106860  \n",
       "5916  1.543278  \n",
       "5917  0.273067  \n",
       "5918  1.483113  \n",
       "5919  3.213251  \n",
       "5920  0.638253  \n",
       "5921  0.614706  \n",
       "5922  1.912616  \n",
       "5923 -0.123466  \n",
       "5924  0.260533  \n",
       "5925  2.415365  \n",
       "5926  1.982029  \n",
       "5927 -0.304676  \n",
       "5928  1.109033  \n",
       "5929  1.906104  \n",
       "5930  0.376991  \n",
       "5931  1.090698  \n",
       "5932  2.018951  \n",
       "5933  0.308224  \n",
       "5934 -0.881957  \n",
       "5935  1.179881  \n",
       "5936  1.768965  \n",
       "5937  2.555747  \n",
       "5938  1.674830  \n",
       "5939  1.242804  \n",
       "5940  3.596345  \n",
       "5941 -0.309062  \n",
       "5942  1.384349  \n",
       "5943 -0.148031  \n",
       "\n",
       "[5944 rows x 8 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_items_df = []\n",
    "for i in range(df.shape[0]):\n",
    "    users_items_df += df['state_history'][i] \n",
    "    \n",
    "users_items_df = pd.DataFrame(users_items_df,columns = ['user_id','item_id',\n",
    "                                                        'price','v1','v2','v3','v4','v5'])\n",
    "users_items_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate the 'v5'\n",
    "new_users_items_df = users_items_df.drop(columns='v5').drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see that the first two covariates variables are features about users \n",
    "# and the forth and fifth variable are features about items\n",
    "# The variable 5 depends on .....\n",
    "\n",
    "user_v1 = users_items_df['v1'].unique()\n",
    "user_v2 = users_items_df['v2'].unique()\n",
    "users_ids = users_items_df['user_id'].unique()\n",
    "users_content= pd.DataFrame({'user_id' : users_ids,'v1':user_v1,'v2':user_v2 })\n",
    "\n",
    "item_v3 = users_items_df['v3'].unique()\n",
    "item_v4 = users_items_df['v4'].unique()\n",
    "item_id = users_items_df['item_id'].unique()\n",
    "items_content= pd.DataFrame({'item_id' : item_id,'v3':item_v3,'v4':item_v4 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87,)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't have all the metadat from all the users\n",
    "users_content['user_id'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = df[df[\"rewards_history\"] > 0].reset_index(drop=True)\n",
    "neg_df = df[df[\"rewards_history\"] == 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "      <th>state_history</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>564.746210</td>\n",
       "      <td>[[36, 0, 540.5126332718834, 1.782519358910701,...</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>512.183329</td>\n",
       "      <td>[[22, 0, 540.5126332718834, 0.1186121387056536...</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>738.509790</td>\n",
       "      <td>[[10, 0, 540.5126332718834, -0.210541174376374...</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>297.761357</td>\n",
       "      <td>[[4, 0, 540.5126332718834, 1.251532030958378, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>992.227109</td>\n",
       "      <td>[[68, 0, 540.5126332718834, 0.6795394801339365...</td>\n",
       "      <td>68</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_history  rewards_history  \\\n",
       "0               7       564.746210   \n",
       "1              14       512.183329   \n",
       "2              19       738.509790   \n",
       "3               4       297.761357   \n",
       "4              13       992.227109   \n",
       "\n",
       "                                       state_history  user_id  item_id_action  \n",
       "0  [[36, 0, 540.5126332718834, 1.782519358910701,...       36               7  \n",
       "1  [[22, 0, 540.5126332718834, 0.1186121387056536...       22              14  \n",
       "2  [[10, 0, 540.5126332718834, -0.210541174376374...       10              19  \n",
       "3  [[4, 0, 540.5126332718834, 1.251532030958378, ...        4               4  \n",
       "4  [[68, 0, 540.5126332718834, 0.6795394801339365...       68              13  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df[\"user_id\"] = [pos_df[\"state_history\"][i][0][0] for i in range(pos_df.shape[0])]\n",
    "pos_df[\"item_id_action\"] = [pos_df[\"state_history\"][i][pos_df[\"action_history\"][i]][1] for i in range(pos_df.shape[0])]\n",
    "pos_df.head()## There are some users that have more than one positive item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_history</th>\n",
       "      <th>rewards_history</th>\n",
       "      <th>state_history</th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id_action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[27, 0, 540.5126332718834, -0.352061653645617...</td>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[46, 0, 540.5126332718834, 2.2085491075520194...</td>\n",
       "      <td>46</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[51, 0, 540.5126332718834, 1.4813623958600743...</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[33, 0, 540.5126332718834, -0.023613619655153...</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[[49, 0, 540.5126332718834, 2.9426282310959033...</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action_history  rewards_history  \\\n",
       "0              22              0.0   \n",
       "1              18              0.0   \n",
       "2              17              0.0   \n",
       "3               9              0.0   \n",
       "4              15              0.0   \n",
       "\n",
       "                                       state_history  user_id  item_id_action  \n",
       "0  [[27, 0, 540.5126332718834, -0.352061653645617...       27              22  \n",
       "1  [[46, 0, 540.5126332718834, 2.2085491075520194...       46              18  \n",
       "2  [[51, 0, 540.5126332718834, 1.4813623958600743...       51              17  \n",
       "3  [[33, 0, 540.5126332718834, -0.023613619655153...       33               9  \n",
       "4  [[49, 0, 540.5126332718834, 2.9426282310959033...       49              15  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_df[\"user_id\"] = [neg_df[\"state_history\"][i][0][0] for i in range(neg_df.shape[0])]\n",
    "neg_df[\"item_id_action\"] = [neg_df[\"state_history\"][i][neg_df[\"action_history\"][i]][1] for i in range(neg_df.shape[0])]\n",
    "neg_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def identity_loss(y_true, y_pred):\n",
    "    \"\"\"Ignore y_true and return the mean of y_pred\n",
    "    \n",
    "    This is a hack to work-around the design of the Keras API that is\n",
    "    not really suited to train networks with a triplet loss by default.\n",
    "    \"\"\"\n",
    "    return tf.reduce_mean(y_pred + 0 * y_true)\n",
    "\n",
    "\n",
    "def margin_comparator_loss(inputs, margin=1.):\n",
    "    \"\"\"Comparator loss for a pair of precomputed similarities\n",
    "    \n",
    "    If the inputs are cosine similarities, they each have range in\n",
    "    (-1, 1), therefore their difference have range in (-2, 2). Using\n",
    "    a margin of 1. can therefore make sense.\n",
    "\n",
    "    If the input similarities are not normalized, it can be beneficial\n",
    "    to use larger values for the margin of the comparator loss.\n",
    "    \"\"\"\n",
    "    positive_pair_sim, negative_pair_sim = inputs\n",
    "    return tf.maximum(negative_pair_sim - positive_pair_sim + margin, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model(The most expensive item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_model_expensive(state):\n",
    "    greater_index = 0\n",
    "    greater_value = 0\n",
    "    \n",
    "    for i in range(len(state)):\n",
    "        if(state[i][2] > greater_value):\n",
    "            greater_value = state[i][2]\n",
    "            greater_index = i\n",
    "    return greater_index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 94429.421857 and Total reward per run: 31476.473952\n"
     ]
    }
   ],
   "source": [
    "number_run = 3\n",
    "generations = 100\n",
    "total_reward = 0\n",
    "\n",
    "for k in range(number_run):\n",
    "    \n",
    "    for i in range(generations):\n",
    "\n",
    "        predicted_item = naive_model_expensive(next_state)\n",
    "\n",
    "        params['recommended_item'] = predicted_item\n",
    "\n",
    "        r = requests.get(url = url_predict, params=params).json()\n",
    "        reward = r['reward']\n",
    "        total_reward += reward\n",
    "        next_state = r['state']\n",
    "        \n",
    "        \n",
    "print(\"Total reward: %f and Total reward per run: %f\"%(total_reward, total_reward/number_run,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model(The cheapest item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_model_cheapest(state):\n",
    "    cheapest_index = 0\n",
    "    cheapest_value =  state[0][2]\n",
    "    \n",
    "    for i in range(len(state)):\n",
    "        if(state[i][2] < cheapest_value):\n",
    "            cheapest_value = state[i][2]\n",
    "            cheapest_index = i\n",
    "            \n",
    "    return cheapest_index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward: 10981.159575 and Total reward per run: 3660.386525\n"
     ]
    }
   ],
   "source": [
    "number_run = 3\n",
    "generations = 100\n",
    "total_reward = 0\n",
    "\n",
    "for k in range(number_run):\n",
    "    \n",
    "    for i in range(generations):\n",
    "\n",
    "        predicted_item = naive_model_cheapest(next_state)\n",
    "\n",
    "        params['recommended_item'] = predicted_item\n",
    "\n",
    "        r = requests.get(url = url_predict, params=params).json()\n",
    "        reward = r['reward']\n",
    "        total_reward += reward\n",
    "        next_state = r['state']\n",
    "        \n",
    "        \n",
    "print(\"Total reward: %f and Total reward per run: %f\"%(total_reward, total_reward/number_run,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Embedding, Flatten, Input, Dense\n",
    "from keras.layers import Lambda, Dot\n",
    "from keras.regularizers import l2\n",
    "from keras.layers.merge import dot, concatenate\n",
    "\n",
    "\n",
    "def build_models(n_users, n_items, latent_dim=64, l2_reg=0):\n",
    "    \"\"\"Build a triplet model and its companion similarity model\n",
    "    \n",
    "    The triplet model is used to train the weights of the companion\n",
    "    similarity model. The triplet model takes 1 user, 1 positive item\n",
    "    (relative to the selected user) and one negative item and is\n",
    "    trained with comparator loss.\n",
    "    \n",
    "    The similarity model takes one user and one item as input and return\n",
    "    compatibility score (aka the match score).\n",
    "    \"\"\"\n",
    "    # Common architectural components for the two models:\n",
    "    # - symbolic input placeholders\n",
    "    user_input = Input((1,), name='user_input')\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "\n",
    "    # - embeddings\n",
    "    l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "    user_layer = Embedding(input_dim=n_users + 1, output_dim=latent_dim, input_length=1,\n",
    "                           name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "    \n",
    "    # The following embedding parameters will be shared to encode both\n",
    "    # the positive and negative items.\n",
    "    item_layer = Embedding(input_dim=n_items + 1, output_dim=latent_dim, input_length=1,\n",
    "                           name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "    user_embedding = Flatten()(user_layer(user_input))\n",
    "    positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "    # - similarity computation between embeddings\n",
    "    positive_similarity = Dot(name=\"positive_similarity\",\n",
    "                              axes=1, normalize=True)(\n",
    "        [user_embedding, positive_item_embedding])\n",
    "    negative_similarity = Dot(name=\"negative_similarity\",\n",
    "                              axes=1, normalize=True)(\n",
    "        [user_embedding, negative_item_embedding])\n",
    "\n",
    "    # The triplet network model, only used for training\n",
    "    triplet_loss = Lambda(margin_comparator_loss,\n",
    "                          name='comparator_loss',\n",
    "                          output_shape=(1,))([positive_similarity, negative_similarity])\n",
    "\n",
    "    triplet_model = Model(inputs=[user_input,\n",
    "                                  positive_item_input,\n",
    "                                  negative_item_input],\n",
    "                          outputs=triplet_loss)\n",
    "    \n",
    "    # The match-score model, only use at inference to rank items for a given\n",
    "    # model: the model weights are shared with the triplet_model therefore\n",
    "    # we do not need to train it and therefore we do not need to plug a loss\n",
    "    # and an optimizer.\n",
    "    match_model = Model(inputs=[user_input, positive_item_input],\n",
    "                        outputs=positive_similarity)\n",
    "    \n",
    "    return triplet_model, match_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triplets(pos_df,max_items):\n",
    "    \"\"\"\n",
    "    Sample negatives at random\n",
    "    \n",
    "    \"\"\"\n",
    "    range_itens = np.arange(max_items)\n",
    "    user_ids = pos_df['user_id'].values\n",
    "    pos_item_ids = pos_df['item_id_action'].values\n",
    "    \n",
    "    \n",
    "    user_pos_items = pos_df.groupby('user_id')['item_id_action'].apply(list)\n",
    "    neg_item_ids = np.array([])\n",
    "    for i in user_ids:\n",
    "        if i in set(user_pos_items.index):\n",
    "            number = np.random.choice([item for item in range_itens \n",
    "                                       if not item in user_pos_items[user_pos_items.index == i]])\n",
    "        else:\n",
    "            number = np.random.choice(range_itens,1)\n",
    "        neg_item_ids = np.append(neg_item_ids,number)\n",
    "    \n",
    "  \n",
    "    return [user_ids, pos_item_ids, neg_item_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.0224\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.9764\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.9556\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 100us/step - loss: 0.8529\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 72us/step - loss: 0.8445\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.7553\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 112us/step - loss: 0.7143\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.6954\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.6616\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.6529\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 69us/step - loss: 0.6286\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.5228\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.4996\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4970\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4953\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.4395\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.4278\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.3501\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4671\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.3907\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 92us/step - loss: 0.4184\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.3528\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.3256\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.3701\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.3161\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3152\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.2827\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.2774\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2629\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.2544\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3167\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1007\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9667\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4251\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8913\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0456\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1138\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0563\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7230\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5791\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8068\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2970\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3057\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9532\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3899\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7040\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6167e-06\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6692\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3063\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7615\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6735\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1535\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4231\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 6ms/step - loss: 1.0289\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 66us/step - loss: 1.0060\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.9417\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 93us/step - loss: 0.9170\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 89us/step - loss: 0.8176\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.7964\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.6836\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.6643\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.6798\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 94us/step - loss: 0.6084\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 76us/step - loss: 0.5930\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 82us/step - loss: 0.5749\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.5331\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.5198\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.4406\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 85us/step - loss: 0.4743\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.4416\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.4180\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 87us/step - loss: 0.3903\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 70us/step - loss: 0.4429\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4466\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 88us/step - loss: 0.2706\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.3050\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3194\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 84us/step - loss: 0.3232\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.3065\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 83us/step - loss: 0.2699\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 78us/step - loss: 0.2988\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 81us/step - loss: 0.2712\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.2952\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9391\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0027\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7092\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7081\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.3262\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7415\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3784\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6808\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6059\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3130\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1107\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2664\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8013\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6526\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1886\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0037\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1844\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9743\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.1652\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0000\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3372\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0656\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 7ms/step - loss: 0.9897\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 71us/step - loss: 0.9428\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.8774\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 143us/step - loss: 0.8242\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.8009\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 90us/step - loss: 0.7505\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.7180\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 61us/step - loss: 0.7494\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 68us/step - loss: 0.6462\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 59us/step - loss: 0.6393\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.6331\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 66us/step - loss: 0.5670\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.5367\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 75us/step - loss: 0.5505\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 67us/step - loss: 0.4525\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 63us/step - loss: 0.4284\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 155us/step - loss: 0.3833\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 58us/step - loss: 0.4454\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 62us/step - loss: 0.4368\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 60us/step - loss: 0.3793\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 74us/step - loss: 0.3202\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 77us/step - loss: 0.4211\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 91us/step - loss: 0.4062\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 139us/step - loss: 0.3545\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.3486\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 101us/step - loss: 0.2934\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 105us/step - loss: 0.2688\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 64us/step - loss: 0.2596\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 80us/step - loss: 0.2748\n",
      "Epoch 1/1\n",
      "64/64 [==============================] - 0s 79us/step - loss: 0.2595\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9358\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6500\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5154\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5502\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5078\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3314\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9648\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3731\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3451\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9930\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.0138\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5216\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4900\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8314\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0105\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2263\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0370\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1089\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9786\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1685\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4546\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.8449\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3274\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0820\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1815\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5630\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8625\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8299\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3309\n",
      "Total reward: 42826.796931 and Total reward per run: 14275.598977\n"
     ]
    }
   ],
   "source": [
    "number_run = 3\n",
    "n_epochs = 30\n",
    "total_reward = 0\n",
    "generations = 100\n",
    "max_items = 30\n",
    "\n",
    "for k in range(number_run):\n",
    "\n",
    "    triplet_model, match_model = build_models(nb_users, nb_items, latent_dim=16, l2_reg=1e-6)\n",
    "    # we plug the identity loss and the a fake target variable ignored by\n",
    "    # the model to be able to use the Keras API to train the triplet model\n",
    "    triplet_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "    fake_y = np.ones_like(pos_df['user_id'])\n",
    "    params = {'user_id': USER_ID}\n",
    "\n",
    "    positive_data = pos_df.copy()\n",
    "    \n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        triplet_inputs = sample_triplets(positive_data, max_items=nb_items)\n",
    "\n",
    "        # Fit the model incrementally by doing a single pass over the\n",
    "        # sampled triplets.\n",
    "        triplet_model.fit(triplet_inputs, fake_y, shuffle=True, epochs=1)\n",
    "\n",
    "    for j in range(generations):\n",
    "\n",
    "\n",
    "        # The user that we need to recommend a product\n",
    "        new_user_id = next_state[0][0]\n",
    "        # Take all the items in the new state\n",
    "        items_ids = np.array([next_state[i][1]\n",
    "                              for i in range(len(next_state))])\n",
    "\n",
    "        # Create an array of the same size of 'items_ids' of all values equal to 'new_user_id'\n",
    "        repeated_user_id = np.empty_like(items_ids)\n",
    "        repeated_user_id.fill(new_user_id)\n",
    "\n",
    "        # predict the product using our model\n",
    "        predicted = match_model.predict([repeated_user_id, items_ids])\n",
    "        predicted_item = np.argmax(predicted)\n",
    "        params['recommended_item'] = predicted_item\n",
    "\n",
    "        # take the reward from the API\n",
    "        r = requests.get(url=url_predict, params=params).json()\n",
    "        reward = r['reward']\n",
    "        total_reward += reward\n",
    "\n",
    "        # (Online learning)Check if the reward is greater than 0 , if yes train again \n",
    "        # the model the sample point\n",
    "        if(reward > 0):\n",
    "            range_itens = np.arange(max_items)\n",
    "            user_pos_items = pos_df.groupby('user_id')['item_id_action'].apply(list)\n",
    "            if new_user_id in set(user_pos_items.index):\n",
    "                neg_item_id = np.random.choice([item for item in range_itens \n",
    "                                           if not item in user_pos_items[user_pos_items.index == new_user_id]])\n",
    "            else:\n",
    "                neg_item_id = np.random.choice(range_itens,1)\n",
    "            \n",
    "           \n",
    "            \n",
    "            triplet_inputs = [[new_user_id], [predicted_item], [neg_item_id]]\n",
    "    \n",
    "            fake_y = np.ones_like([1])\n",
    "            triplet_model.fit(triplet_inputs, fake_y, shuffle=True,\n",
    "                               batch_size=64, epochs=1)\n",
    "    \n",
    "            \n",
    "        # Take the nex_state\n",
    "        next_state = r['state']\n",
    "\n",
    "\n",
    "print(\"Total reward: %f and Total reward per run: %f\" %(total_reward, total_reward/number_run,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, Dense, Dropout\n",
    "from keras.layers import Concatenate, Lambda\n",
    "from keras.regularizers import l2\n",
    "\n",
    "\n",
    "def make_interaction_mlp(input_dim, n_hidden=1, hidden_size=64,\n",
    "                         dropout=0, l2_reg=None):\n",
    "    \"\"\"\n",
    "    Build the shared multi layer perceptron\n",
    "\n",
    "    \"\"\"\n",
    "    mlp = Sequential()\n",
    "    if n_hidden == 0:\n",
    "        # Plug the output unit directly: this is a simple\n",
    "        # linear regression model. Not dropout required.\n",
    "        mlp.add(Dense(1, input_dim=input_dim,\n",
    "                      activation='relu', kernel_regularizer=l2_reg))\n",
    "    else:\n",
    "        mlp.add(Dense(hidden_size, input_dim=input_dim,\n",
    "                      activation='relu', kernel_regularizer=l2_reg))\n",
    "        mlp.add(Dropout(dropout))\n",
    "        for i in range(n_hidden - 1):\n",
    "            mlp.add(Dense(hidden_size, activation='relu',\n",
    "                          kernel_regularizer=l2_reg))\n",
    "            mlp.add(Dropout(dropout))\n",
    "        mlp.add(Dense(1, activation='relu', kernel_regularizer=l2_reg))\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def build_models(n_users, n_items, user_dim=32, item_dim=64,\n",
    "                 n_hidden=1, hidden_size=64, dropout=0, l2_reg=0):\n",
    "    \"\"\"\n",
    "    Build models to train a deep triplet network\n",
    "\n",
    "    \"\"\"\n",
    "    user_input = Input((1,), name='user_input')\n",
    "    positive_item_input = Input((1,), name='positive_item_input')\n",
    "    negative_item_input = Input((1,), name='negative_item_input')\n",
    "    positive_meta_input = Input((2,), name='positive_meta_input')\n",
    "    negative_meta_input = Input((2,), name='negative_meta_input')\n",
    "\n",
    "    l2_reg = None if l2_reg == 0 else l2(l2_reg)\n",
    "    user_layer = Embedding(n_users + 1, user_dim, input_length=1,\n",
    "                           name='user_embedding', embeddings_regularizer=l2_reg)\n",
    "\n",
    "    # The following embedding parameters will be shared to encode both\n",
    "    # the positive and negative items.\n",
    "    item_layer = Embedding(n_items + 1, item_dim, input_length=1,\n",
    "                           name=\"item_embedding\", embeddings_regularizer=l2_reg)\n",
    "\n",
    "    user_embedding = Flatten()(user_layer(user_input))\n",
    "    positive_item_embedding = Flatten()(item_layer(positive_item_input))\n",
    "    negative_item_embedding = Flatten()(item_layer(negative_item_input))\n",
    "\n",
    "    # Similarity computation between embeddings using a MLP similarity\n",
    "    positive_embeddings_pair = Concatenate(name=\"positive_embeddings_pair\")(\n",
    "        [user_embedding, positive_item_embedding, positive_meta_input])\n",
    "    positive_embeddings_pair = Dropout(dropout)(positive_embeddings_pair)\n",
    "\n",
    "    negative_embeddings_pair = Concatenate(name=\"negative_embeddings_pair\")(\n",
    "        [user_embedding, negative_item_embedding, negative_meta_input])\n",
    "    negative_embeddings_pair = Dropout(dropout)(negative_embeddings_pair)\n",
    "\n",
    "    # Instanciate the shared similarity architecture\n",
    "    interaction_layers = make_interaction_mlp(\n",
    "        user_dim + item_dim + 2, n_hidden=n_hidden, hidden_size=hidden_size,\n",
    "        dropout=dropout, l2_reg=l2_reg)\n",
    "\n",
    "    positive_similarity = interaction_layers(positive_embeddings_pair)\n",
    "    negative_similarity = interaction_layers(negative_embeddings_pair)\n",
    "\n",
    "    # The triplet network model, only used for training\n",
    "    triplet_loss = Lambda(margin_comparator_loss, output_shape=(1,),\n",
    "                          name='comparator_loss')(\n",
    "        [positive_similarity, negative_similarity])\n",
    "\n",
    "    deep_triplet_model = Model(inputs=[user_input,\n",
    "                                       positive_item_input,\n",
    "                                       negative_item_input,\n",
    "                                       positive_meta_input,\n",
    "                                       negative_meta_input\n",
    "                                       ],\n",
    "                               outputs=[triplet_loss])\n",
    "\n",
    "    # The match-score model, only used at inference\n",
    "    deep_match_model = Model(inputs=[user_input, positive_item_input, positive_meta_input],\n",
    "                             outputs=[positive_similarity])\n",
    "\n",
    "    return deep_match_model, deep_triplet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triplets(pos_df, items_content, max_items):\n",
    "    \"\"\"\n",
    "    Sample the data and put in the format \n",
    "    [user_ids, pos_item_ids, neg_item_ids,pos_item_metadata,neg_item_metadata]\n",
    "\n",
    "    \"\"\"\n",
    "    range_itens = np.arange(max_items)\n",
    "    user_ids = pos_df['user_id'].values\n",
    "    \n",
    "\n",
    "    pos_item_ids = pos_df['item_id_action'].values\n",
    "    pos_item_metadata = items_content.loc[pos_item_ids][['v3', 'v4']].values\n",
    "\n",
    "    \n",
    "    user_pos_items = pos_df.groupby('user_id')['item_id_action'].apply(list)\n",
    "    neg_item_ids = np.array([])\n",
    "    for i in user_ids:\n",
    "        if i in set(user_pos_items.index):\n",
    "            number = np.random.choice([item for item in range_itens \n",
    "                                       if not item in user_pos_items[user_pos_items.index == i]])\n",
    "        else:\n",
    "            number = np.random.choice(range_itens, 1)\n",
    "        neg_item_ids = np.append(neg_item_ids, number)\n",
    "\n",
    "    neg_item_metadata = items_content.loc[neg_item_ids][['v3', 'v4']].values\n",
    "\n",
    "    return [user_ids, pos_item_ids, neg_item_ids, pos_item_metadata, neg_item_metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = dict(\n",
    "    user_dim=50,\n",
    "    item_dim=15,\n",
    "    n_hidden=1,\n",
    "    hidden_size=16,\n",
    "    dropout=0.5,\n",
    "    l2_reg=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-196-29c1ebec04b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Sample new negatives to build different triplets at each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtriplet_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_triplets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitems_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_items\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_items\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Fit the model incrementally by doing a single pass over the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-ce9c8d775bb3>\u001b[0m in \u001b[0;36msample_triplets\u001b[0;34m(pos_df, new_users_items_df, max_items)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpos_item_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'item_id_action'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpos_item_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_users_items_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos_item_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'v2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'v3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'v4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   3907\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3908\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3909\u001b[0;31m                 \u001b[0mlevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3910\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3911\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_id'"
     ]
    }
   ],
   "source": [
    "number_run = 3\n",
    "n_epochs = 30\n",
    "total_reward = 0\n",
    "generations = 100\n",
    "max_items = 30 \n",
    "\n",
    "for k in range(number_run):\n",
    "\n",
    "    deep_match_model, deep_triplet_model = build_models(nb_users, nb_items,**hyper_parameters)\n",
    "    # we plug the identity loss and the a fake target variable ignored by\n",
    "    # the model to be able to use the Keras API to train the triplet model\n",
    "    deep_triplet_model.compile(loss=identity_loss, optimizer=\"adam\")\n",
    "    fake_y = np.ones_like(pos_df['user_id'])\n",
    "    params = {'user_id': USER_ID}\n",
    "    \n",
    "    positive_data = pos_df.copy()\n",
    "    \n",
    "    # Training the model \n",
    "    for i in range(n_epochs):\n",
    "        # Sample new negatives to build different triplets at each epoch\n",
    "        triplet_inputs = sample_triplets(positive_data,items_content, max_items=nb_items)\n",
    "\n",
    "        # Fit the model incrementally by doing a single pass over the\n",
    "        # sampled triplets.\n",
    "        deep_triplet_model.fit(triplet_inputs, fake_y, shuffle=True,\n",
    "                               batch_size=64, epochs=1)\n",
    "\n",
    "\n",
    "    for j in range(generations):\n",
    "        \n",
    "        # Predicting\n",
    "        new_user_id = next_state[0][0]\n",
    "        items_ids = np.array([next_state[i][1] for i in range(len(next_state))])\n",
    "        repeated_user_id = np.empty_like(items_ids)\n",
    "        repeated_user_id.fill(new_user_id)\n",
    "\n",
    "        pos_metadata = items_content.loc[items_ids][['v3', 'v4']].values\n",
    "        predicted = deep_match_model.predict([repeated_user_id, items_ids, pos_metadata])\n",
    "        predicted_item = np.argmax(predicted)\n",
    "        params['recommended_item'] = predicted_item\n",
    "\n",
    "        r = requests.get(url=url_predict, params=params).json()\n",
    "        reward = r['reward']\n",
    "        total_reward += reward\n",
    "\n",
    "        # Online learning\n",
    "        if(reward > 0):\n",
    "            range_itens = np.arange(max_items)\n",
    "            user_pos_items = positive_data.groupby('user_id')['item_id_action'].apply(list)\n",
    "            if new_user_id in set(user_pos_items.index):\n",
    "                neg_item_id = np.random.choice([item for item in range_itens \n",
    "                                           if not item in user_pos_items[user_pos_items.index == new_user_id]])\n",
    "            else:\n",
    "                neg_item_id = np.random.choice(range_itens,1)\n",
    "            \n",
    "            pos_item_metadata = items_content.set_index('item_id').loc[predicted_item].values\n",
    "            neg_item_metadata = items_content.set_index('item_id').loc[neg_item_id].values\n",
    "            \n",
    "            triplet_inputs = [[new_user_id], [predicted_item], [neg_item_id], \n",
    "                              pos_item_metadata.reshape((1,2)), neg_item_metadata.reshape((1,2))]\n",
    "    \n",
    "            fake_y = np.ones_like([1])\n",
    "            deep_triplet_model.fit(triplet_inputs, fake_y, shuffle=True,\n",
    "                               batch_size = 8, epochs=1)\n",
    "\n",
    "        next_state = r['state']\n",
    "\n",
    "print(\"Total reward: %f and Total reward per run: %f\"%(total_reward, total_reward/number_run))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
