{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gvTen8A0xXD-"
   },
   "source": [
    "# Project on recommander systems : First Environment\n",
    "\n",
    "#### Author : Raymond KUOCH and Alexandre MAXINSANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JJDefommxXED",
    "outputId": "453cfd63-7f89-49e0-cb4a-29a97e32f91f"
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Concatenate, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cdThvwlxXER"
   },
   "outputs": [],
   "source": [
    "# Define IP adress of each environnement and the login\n",
    "url_env = {\"first_env\":\"http://52.47.62.31\", \n",
    "           \"second_env\":\"http://35.180.254.42\", \n",
    "           \"third_env\":\"http://35.180.178.243\"}\n",
    "user_id = 'Y6EKWA0GK1D0VCTN0RT7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v-yxzWtaxXEZ"
   },
   "source": [
    "## First environnement : Explicit feedback without covariates\n",
    "\n",
    "### 1) Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "p2k4FuU6xXEc",
    "outputId": "6e2855ba-b4bb-41a9-a5b4-03d081a44e5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['item_history', 'nb_items', 'nb_users', 'next_item', 'next_user', 'rating_history', 'user_history'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_reset = url_env[\"first_env\"] + \"/reset\"\n",
    "url_predict = url_env[\"first_env\"] + \"/predict\"\n",
    "params = {\"user_id\" : user_id}\n",
    "\n",
    "def load_data(url_reset,params) :\n",
    "    r = requests.get(url=url_reset, params=params)\n",
    "    data = r.json()\n",
    "    return data\n",
    "\n",
    "def mean_square_error(true, predicted):\n",
    "    return (true - predicted) ** 2\n",
    "\n",
    "def mean_absolute_error(true, predicted):\n",
    "    return np.abs(true - predicted)\n",
    "\n",
    "data = load_data(url_reset,params)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "9aW_q--ExXEm",
    "outputId": "6a5a42bd-efce-48d3-efdc-531268d02c4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>171</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "      <td>284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>148</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>291</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0       31      171       2\n",
       "1       66      284       1\n",
       "2       34       36       5\n",
       "3       94      148       2\n",
       "4       77      291       5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_history = data[\"user_history\"]\n",
    "item_history = data[\"item_history\"]\n",
    "rating_history = data[\"rating_history\"]\n",
    "\n",
    "train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "train_ratings.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OG7-hB0vxXEt"
   },
   "source": [
    "### 2) Prediction model\n",
    "\n",
    "#### 2.1) Constant agent\n",
    "\n",
    "Let's start with a baseline : constant agent, for instance an agent who predicts the value 3 for each pair (user_id, item_id).\n",
    "\n",
    "The performance metric will be MSE over 1000 steps on 3 independent run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "yLkoZncIxXEv",
    "outputId": "c1270bf3-4764-443b-96ba-ee2a420bed0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE over 1000 samples on the run 0 : 1.8610 \n",
      "MSE over 1000 samples on the run 1 : 2.0480 \n",
      "MSE over 1000 samples on the run 2 : 1.9960 \n",
      "--------------------------------------------\n",
      "Mean of the MSE on 3 independant runs 1.9683\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "\n",
    "    prediction = 3\n",
    "    params[\"predicted_score\"] = prediction\n",
    "\n",
    "    mse = 0\n",
    "    \n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "    \n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "    \n",
    "print(\"--------------------------------------------\")\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f\" % (mean/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40k-YcASxXE8"
   },
   "source": [
    "#### 2.2) Matrix factorization approach with SGD\n",
    "\n",
    "We will use the Surprise library which provides a set of tools for recommendation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PB6xuT1TyQ13"
   },
   "outputs": [],
   "source": [
    "def recommender_system_svd (train_ratings, embedding_size) : \n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    train_spr = Dataset.load_from_df(train_ratings, reader).build_full_trainset()\n",
    "    model = SVD(n_factors = embedding_size)\n",
    "    model.fit(train_spr)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will study the influence of the embedding size on the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "colab_type": "code",
    "id": "4IcwxuFf1VLO",
    "outputId": "71929a37-dd45-47fa-ff24-8393090be8e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 20\n",
      "MSE over 1000 samples on the run 0 : 2.2764 \n",
      "MSE over 1000 samples on the run 1 : 1.7170 \n",
      "MSE over 1000 samples on the run 2 : 2.1954 \n",
      "Mean of the MSE on 3 independant runs 2.0629 \n",
      "-------------------------------------------\n",
      "Embedding size : 30\n",
      "MSE over 1000 samples on the run 0 : 1.4599 \n",
      "MSE over 1000 samples on the run 1 : 1.6912 \n",
      "MSE over 1000 samples on the run 2 : 1.6452 \n",
      "Mean of the MSE on 3 independant runs 1.5987 \n",
      "-------------------------------------------\n",
      "Embedding size : 40\n",
      "MSE over 1000 samples on the run 0 : 1.7658 \n",
      "MSE over 1000 samples on the run 1 : 1.8129 \n",
      "MSE over 1000 samples on the run 2 : 1.9818 \n",
      "Mean of the MSE on 3 independant runs 1.8535 \n",
      "-------------------------------------------\n",
      "Embedding size : 50\n",
      "MSE over 1000 samples on the run 0 : 1.6294 \n",
      "MSE over 1000 samples on the run 1 : 1.9606 \n",
      "MSE over 1000 samples on the run 2 : 1.6424 \n",
      "Mean of the MSE on 3 independant runs 1.7441 \n",
      "-------------------------------------------\n",
      "Embedding size : 60\n",
      "MSE over 1000 samples on the run 0 : 1.8598 \n",
      "MSE over 1000 samples on the run 1 : 1.8157 \n",
      "MSE over 1000 samples on the run 2 : 1.8394 \n",
      "Mean of the MSE on 3 independant runs 1.8383 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = load_data(url_reset,params)\n",
    "user_history = data[\"user_history\"]\n",
    "item_history = data[\"item_history\"]\n",
    "rating_history = data[\"rating_history\"]\n",
    "train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "nb_users = data[\"nb_users\"]\n",
    "nb_items = data[\"nb_items\"]\n",
    "next_user = data[\"next_user\"]\n",
    "next_item = data[\"next_item\"]\n",
    "\n",
    "nb_samples = 1000\n",
    "\n",
    "for k in np.arange(20, 70, 10) : \n",
    "    mean = 0\n",
    "    print(\"Embedding size : %d\" % (k))\n",
    "    for i in range(0, 3) : \n",
    "        mse = 0\n",
    "        model = recommender_system_svd(train_ratings, embedding_size=k)\n",
    "\n",
    "        for j in range(nb_samples) : \n",
    "            time.sleep(0.5)\n",
    "            prediction = model.predict(uid = next_user, iid = next_user).est\n",
    "            params[\"predicted_score\"] = prediction\n",
    "            next_data = requests.get(url=url_predict, params=params).json()\n",
    "            rating = next_data[\"rating\"]\n",
    "            next_user = next_data[\"next_user\"]\n",
    "            next_item = next_data[\"next_item\"]\n",
    "            mse += mean_square_error(rating, prediction)\n",
    "\n",
    "        mean += mse/nb_samples\n",
    "        print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "    print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSmnfhvRwXPJ"
   },
   "source": [
    "The performance of the SGD is equivalent to that of a constant agent : it does not improve it at all. We will now use a hidden layer neural network architecture to improve the performance of the recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vg3sAfzXufgw"
   },
   "source": [
    "According to the results above, **The size of the latent space to be preferred is 50, as its size brings the best MSE in average**. According to some papers, the best size to use is given by a $\\max((\\# users)^{1/4} \\dot (\\# items)^{1/4}, 50)$. In our case : #users = 100 and #items = 300. So we gonna use 50 as the embedding size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YR-ccujyBiT"
   },
   "source": [
    "#### 2.3) Matrix factorization approach with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbhvsybTzACO"
   },
   "outputs": [],
   "source": [
    "def recommender_system_embedding(train_x, train_y, embedding_size, nb_users, nb_items) :\n",
    "    \n",
    "    user_id_input = Input(shape=[1],name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "    \n",
    "    user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                               input_length=1, name='user_embedding')(user_id_input)\n",
    "    item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                               input_length=1, name='item_embedding')(item_id_input)\n",
    "    \n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "    y = Dot(axes=1)([user_vecs, item_vecs])\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=\"mse\")\n",
    "    history = model.fit(train_x, train_y, batch_size=64, epochs=50, validation_split=0.1,shuffle=True)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 10.4987 - val_loss: 10.6530\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 9.9447 - val_loss: 9.0436\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 6.3941 - val_loss: 3.9936\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 2.2409 - val_loss: 1.3135\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.8755 - val_loss: 0.7423\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.6257 - val_loss: 0.6335\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.5769 - val_loss: 0.6010\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.5474 - val_loss: 0.5756\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5066 - val_loss: 0.5290\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4523 - val_loss: 0.4786\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3926 - val_loss: 0.4267\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3352 - val_loss: 0.3756\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2863 - val_loss: 0.3333\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.2460 - val_loss: 0.2998\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2146 - val_loss: 0.2736\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1903 - val_loss: 0.2525\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1720 - val_loss: 0.2376\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.1581 - val_loss: 0.2252\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.1481 - val_loss: 0.2169\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.1395 - val_loss: 0.2106\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1333 - val_loss: 0.2052\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1280 - val_loss: 0.1996\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1232 - val_loss: 0.1974\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1194 - val_loss: 0.1939\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1153 - val_loss: 0.1921\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1117 - val_loss: 0.1881\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1076 - val_loss: 0.1877\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1041 - val_loss: 0.1882\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1005 - val_loss: 0.1849\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0970 - val_loss: 0.1847\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0928 - val_loss: 0.1826\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 19us/step - loss: 0.0888 - val_loss: 0.1813\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0852 - val_loss: 0.1793\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.0814 - val_loss: 0.1795\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 20us/step - loss: 0.0774 - val_loss: 0.1777\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0739 - val_loss: 0.1766\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0703 - val_loss: 0.1752\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0664 - val_loss: 0.1747\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0629 - val_loss: 0.1746\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.0600 - val_loss: 0.1733\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0564 - val_loss: 0.1734\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0531 - val_loss: 0.1744\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0502 - val_loss: 0.1737\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0471 - val_loss: 0.1747\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0442 - val_loss: 0.1735\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0410 - val_loss: 0.1751\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0384 - val_loss: 0.1749\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0358 - val_loss: 0.1760\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0332 - val_loss: 0.1772\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0309 - val_loss: 0.1773\n",
      "MSE over 1000 samples on the run 0 : 0.1683 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 10.4996 - val_loss: 10.6568\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 9.9951 - val_loss: 9.1848\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 6.5536 - val_loss: 4.1072\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 2.2820 - val_loss: 1.3313\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.8779 - val_loss: 0.7384\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.6275 - val_loss: 0.6368\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.5821 - val_loss: 0.6082\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.5603 - val_loss: 0.5885\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5349 - val_loss: 0.5594\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4975 - val_loss: 0.5252\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.4506 - val_loss: 0.4778\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.3960 - val_loss: 0.4256\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.3411 - val_loss: 0.3776\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.2906 - val_loss: 0.3305\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2479 - val_loss: 0.2939\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.2146 - val_loss: 0.2645\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1896 - val_loss: 0.2430\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.1708 - val_loss: 0.2271\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.1576 - val_loss: 0.2170\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.1474 - val_loss: 0.2073\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1396 - val_loss: 0.2019\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1332 - val_loss: 0.1970\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1279 - val_loss: 0.1940\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.1236 - val_loss: 0.1898\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.1193 - val_loss: 0.1881\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1156 - val_loss: 0.1880\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1117 - val_loss: 0.1822\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1078 - val_loss: 0.1834\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 12us/step - loss: 0.1039 - val_loss: 0.1806\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.1001 - val_loss: 0.1788\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0962 - val_loss: 0.1796\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0920 - val_loss: 0.1759\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0877 - val_loss: 0.1743\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0837 - val_loss: 0.1732\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0799 - val_loss: 0.1710\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 12us/step - loss: 0.0757 - val_loss: 0.1700\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0717 - val_loss: 0.1689\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0679 - val_loss: 0.1698\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0643 - val_loss: 0.1682\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0607 - val_loss: 0.1698\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0572 - val_loss: 0.1671\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0537 - val_loss: 0.1698\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0505 - val_loss: 0.1697\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0473 - val_loss: 0.1708\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0445 - val_loss: 0.1687\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0415 - val_loss: 0.1730\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0387 - val_loss: 0.1722\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0360 - val_loss: 0.1730\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0334 - val_loss: 0.1750\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 11us/step - loss: 0.0310 - val_loss: 0.1742\n",
      "MSE over 1000 samples on the run 1 : 0.1824 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 10.4998 - val_loss: 10.6561\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 9.9694 - val_loss: 9.1306\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 19us/step - loss: 6.5464 - val_loss: 4.1534\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 20us/step - loss: 2.3195 - val_loss: 1.3352\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.8836 - val_loss: 0.7333\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.6268 - val_loss: 0.6311\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.5842 - val_loss: 0.6093\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.5660 - val_loss: 0.5962\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5464 - val_loss: 0.5751\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.5161 - val_loss: 0.5451\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4743 - val_loss: 0.5077\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.4245 - val_loss: 0.4614\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3721 - val_loss: 0.4150\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3215 - val_loss: 0.3721\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.2783 - val_loss: 0.3305\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.2418 - val_loss: 0.3006\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2131 - val_loss: 0.2743\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1904 - val_loss: 0.2558\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1743 - val_loss: 0.2397\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1608 - val_loss: 0.2276\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1512 - val_loss: 0.2196\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1430 - val_loss: 0.2102\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1363 - val_loss: 0.2046\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1310 - val_loss: 0.2013\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1262 - val_loss: 0.1956\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1216 - val_loss: 0.1961\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1177 - val_loss: 0.1916\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1135 - val_loss: 0.1888\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1095 - val_loss: 0.1868\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1057 - val_loss: 0.1853\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1013 - val_loss: 0.1823\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0973 - val_loss: 0.1819\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0930 - val_loss: 0.1787\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0884 - val_loss: 0.1776\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0841 - val_loss: 0.1763\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0798 - val_loss: 0.1743\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0750 - val_loss: 0.1716\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 12us/step - loss: 0.0709 - val_loss: 0.1713\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0666 - val_loss: 0.1706\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0625 - val_loss: 0.1695\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0590 - val_loss: 0.1691\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0547 - val_loss: 0.1689\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0515 - val_loss: 0.1694\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0481 - val_loss: 0.1688\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0450 - val_loss: 0.1670\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0421 - val_loss: 0.1681\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0390 - val_loss: 0.1698\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 12us/step - loss: 0.0361 - val_loss: 0.1696\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0336 - val_loss: 0.1727\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0312 - val_loss: 0.1700\n",
      "MSE over 1000 samples on the run 2 : 0.1824 \n",
      "Mean of the MSE on 3 independant runs 0.1777 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size)\n",
    "      \n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    mse = 0\n",
    "    model, history = recommender_system_embedding(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f05dbd2a748>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    We observe that the validation loss starts to increase in the last epochs. In order to avoid this which is a sign of overfitting, the training is prepared to be stopped before this increase. To do this, we will use early stopping.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_system_embedding_early_stopping(train_x, train_y, embedding_size, nb_users, nb_items) :\n",
    "    \n",
    "    user_id_input = Input(shape=[1],name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "    \n",
    "    user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                               input_length=1, name='user_embedding')(user_id_input)\n",
    "    item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                               input_length=1, name='item_embedding')(item_id_input)\n",
    "    \n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "    y = Dot(axes=1)([user_vecs, item_vecs])\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y)\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=\"mse\")\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "    history = model.fit(train_x, train_y, batch_size=64, epochs=50, \n",
    "                        validation_split=0.1, shuffle=True, \n",
    "                        callbacks=[early_stopping])\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 63us/step - loss: 10.4349 - val_loss: 10.4726\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 9.7633 - val_loss: 8.6023\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 5.9422 - val_loss: 3.5180\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 1.9745 - val_loss: 1.1325\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.8039 - val_loss: 0.6862\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.6094 - val_loss: 0.6154\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.5775 - val_loss: 0.6023\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.5657 - val_loss: 0.5895\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.5534 - val_loss: 0.5795\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5348 - val_loss: 0.5620\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5103 - val_loss: 0.5398\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.4803 - val_loss: 0.5120\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.4445 - val_loss: 0.4747\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4073 - val_loss: 0.4396\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.3677 - val_loss: 0.4061\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.3302 - val_loss: 0.3743\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2930 - val_loss: 0.3390\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.2577 - val_loss: 0.3130\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 19us/step - loss: 0.2254 - val_loss: 0.2812\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.1969 - val_loss: 0.2587\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1731 - val_loss: 0.2379\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1548 - val_loss: 0.2217\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1407 - val_loss: 0.2079\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.1303 - val_loss: 0.1982\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.1222 - val_loss: 0.1883\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.1155 - val_loss: 0.1823\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1105 - val_loss: 0.1790\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1058 - val_loss: 0.1727\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.1014 - val_loss: 0.1700\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 18us/step - loss: 0.0976 - val_loss: 0.1662\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0936 - val_loss: 0.1645\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0898 - val_loss: 0.1632\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0863 - val_loss: 0.1599\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0823 - val_loss: 0.1610\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0786 - val_loss: 0.1580\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0752 - val_loss: 0.1555\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0718 - val_loss: 0.1540\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0678 - val_loss: 0.1541\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0646 - val_loss: 0.1532\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0610 - val_loss: 0.1517\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0580 - val_loss: 0.1497\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0546 - val_loss: 0.1532\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0517 - val_loss: 0.1510\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0488 - val_loss: 0.1493\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 16us/step - loss: 0.0457 - val_loss: 0.1512\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0430 - val_loss: 0.1517\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0404 - val_loss: 0.1533\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 17us/step - loss: 0.0380 - val_loss: 0.1515\n",
      "MSE over 1000 samples on the run 0 : 0.1524 \n",
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 9.2177 - val_loss: 9.1000\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 8.7153 - val_loss: 7.6783\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 5.5582 - val_loss: 3.3428\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 1.9745 - val_loss: 1.1299\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.8075 - val_loss: 0.6580\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 12us/step - loss: 0.5929 - val_loss: 0.5725\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.5523 - val_loss: 0.5546\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.5342 - val_loss: 0.5412\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5114 - val_loss: 0.5221\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.4797 - val_loss: 0.4880\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4380 - val_loss: 0.4470\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3903 - val_loss: 0.4080\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.3437 - val_loss: 0.3668\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3013 - val_loss: 0.3307\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.2645 - val_loss: 0.3019\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.2327 - val_loss: 0.2739\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2057 - val_loss: 0.2507\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1826 - val_loss: 0.2310\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1632 - val_loss: 0.2137\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1478 - val_loss: 0.2011\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1357 - val_loss: 0.1921\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1264 - val_loss: 0.1838\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1192 - val_loss: 0.1779\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1137 - val_loss: 0.1746\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1089 - val_loss: 0.1697\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1050 - val_loss: 0.1684\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1016 - val_loss: 0.1664\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0980 - val_loss: 0.1653\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0947 - val_loss: 0.1653\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0915 - val_loss: 0.1629\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0881 - val_loss: 0.1629\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0847 - val_loss: 0.1604\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0812 - val_loss: 0.1611\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0780 - val_loss: 0.1617\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 12us/step - loss: 0.0747 - val_loss: 0.1618\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0711 - val_loss: 0.1616\n",
      "MSE over 1000 samples on the run 1 : 0.1527 \n",
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 61us/step - loss: 10.3062 - val_loss: 10.1669\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 9.8099 - val_loss: 8.7366\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 6.4298 - val_loss: 3.8932\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 2.2173 - val_loss: 1.2156\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.8145 - val_loss: 0.6714\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5696 - val_loss: 0.5860\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5270 - val_loss: 0.5642\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.5086 - val_loss: 0.5493\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4882 - val_loss: 0.5254\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.4588 - val_loss: 0.4994\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.4225 - val_loss: 0.4619\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.3812 - val_loss: 0.4241\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.3401 - val_loss: 0.3861\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.3006 - val_loss: 0.3507\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2634 - val_loss: 0.3175\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2309 - val_loss: 0.2899\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.2024 - val_loss: 0.2656\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1789 - val_loss: 0.2442\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1598 - val_loss: 0.2278\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1452 - val_loss: 0.2160\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1338 - val_loss: 0.2063\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.1248 - val_loss: 0.1984\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1183 - val_loss: 0.1926\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.1129 - val_loss: 0.1902\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1079 - val_loss: 0.1859\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1037 - val_loss: 0.1841\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.1004 - val_loss: 0.1842\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0966 - val_loss: 0.1845\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0932 - val_loss: 0.1803\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0894 - val_loss: 0.1788\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0860 - val_loss: 0.1791\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0829 - val_loss: 0.1792\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0794 - val_loss: 0.1782\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0757 - val_loss: 0.1782\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 13us/step - loss: 0.0721 - val_loss: 0.1759\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0691 - val_loss: 0.1769\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0653 - val_loss: 0.1761\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 15us/step - loss: 0.0621 - val_loss: 0.1764\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 14us/step - loss: 0.0588 - val_loss: 0.1772\n",
      "MSE over 1000 samples on the run 2 : 0.1104 \n",
      "Mean of the MSE on 3 independant runs 0.1385 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_embedding_early_stopping(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    The mean of the MSE is a bit improved when we use Early Stopping, the MSE going from almost 0.18 to 0.14. As a result, we will keep using Early Stopping with other methods with FC layers.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4) Matrix factorization approach with embeddings and non linearities (one FC layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_system_deep_1(train_x, train_y, embedding_size, nb_users, nb_items) :\n",
    "    \n",
    "    user_id_input = Input(shape=[1],name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "    embedding_size = embedding_size\n",
    "    user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "    item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "    input_vecs = Concatenate()([user_vecs, item_vecs])\n",
    "    input_vecs = Dropout(0.2)(input_vecs)\n",
    "    x = Dense(64, activation='relu')(input_vecs)\n",
    "    y = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y)\n",
    "    model.compile(optimizer='adam', loss='MSE')\n",
    "    # early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "    # history = model.fit(train_x, train_y, batch_size=64, epochs=50, \n",
    "    #                    validation_split=0.1, shuffle=True, \n",
    "    #                    callbacks=[early_stopping])\n",
    "    history = model.fit(train_x, train_y, batch_size=64, epochs=50, \n",
    "                        validation_split=0.1, shuffle=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 131us/step - loss: 3.8290 - val_loss: 0.7933\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.7445 - val_loss: 0.7465\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.7214 - val_loss: 0.7434\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6971 - val_loss: 0.7148\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.6458 - val_loss: 0.6773\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.6206 - val_loss: 0.6360\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5928 - val_loss: 0.6312\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5848 - val_loss: 0.6286\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5737 - val_loss: 0.6276\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.5655 - val_loss: 0.6221\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.5602 - val_loss: 0.6246\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5577 - val_loss: 0.6103\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5446 - val_loss: 0.6116\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.5438 - val_loss: 0.6029\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.5314 - val_loss: 0.5987\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.5289 - val_loss: 0.5946\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.5025 - val_loss: 0.5527\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.4644 - val_loss: 0.4975\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.4217 - val_loss: 0.4601\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3902 - val_loss: 0.4351\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.3701 - val_loss: 0.4402\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3639 - val_loss: 0.4114\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3454 - val_loss: 0.3952\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3380 - val_loss: 0.3742\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.3194 - val_loss: 0.3505\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.2989 - val_loss: 0.3106\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.2636 - val_loss: 0.2777\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2326 - val_loss: 0.2402\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.2102 - val_loss: 0.2176\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1990 - val_loss: 0.2049\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1899 - val_loss: 0.1875\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1787 - val_loss: 0.1885\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.1709 - val_loss: 0.1821\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.1676 - val_loss: 0.1845\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.1651 - val_loss: 0.1770\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1561 - val_loss: 0.1682\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.1548 - val_loss: 0.1676\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1514 - val_loss: 0.1608\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1460 - val_loss: 0.1606\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1437 - val_loss: 0.1517\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1438 - val_loss: 0.1572\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.1413 - val_loss: 0.1587\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.1366 - val_loss: 0.1550\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1357 - val_loss: 0.1531\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1346 - val_loss: 0.1505\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1306 - val_loss: 0.1465\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1319 - val_loss: 0.1571\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1289 - val_loss: 0.1505\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.1291 - val_loss: 0.1504\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.1259 - val_loss: 0.1476\n",
      "MSE over 1000 samples on the run 0 : 0.1371 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 147us/step - loss: 3.9238 - val_loss: 0.7243\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.7331 - val_loss: 0.6463\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.7043 - val_loss: 0.6493\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.6827 - val_loss: 0.6124\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.6372 - val_loss: 0.5699\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.5997 - val_loss: 0.5548\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5864 - val_loss: 0.5561\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.5760 - val_loss: 0.5506\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5673 - val_loss: 0.5527\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.5567 - val_loss: 0.5485\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5442 - val_loss: 0.5391\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.5331 - val_loss: 0.5346\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5074 - val_loss: 0.4925\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.4674 - val_loss: 0.4224\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4038 - val_loss: 0.3562\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3562 - val_loss: 0.3276\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.3398 - val_loss: 0.3129\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3215 - val_loss: 0.3091\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3152 - val_loss: 0.3073\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3093 - val_loss: 0.2994\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3028 - val_loss: 0.2976\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2988 - val_loss: 0.2943\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2946 - val_loss: 0.3002\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2908 - val_loss: 0.2969\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2847 - val_loss: 0.2960\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.2879 - val_loss: 0.2986\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2826 - val_loss: 0.3051\n",
      "MSE over 1000 samples on the run 1 : 0.2550 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 1s 138us/step - loss: 4.1963 - val_loss: 0.7026\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.6635 - val_loss: 0.5981\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.6264 - val_loss: 0.5581\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.5911 - val_loss: 0.5306\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.5401 - val_loss: 0.4906\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5252 - val_loss: 0.4912\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5130 - val_loss: 0.4910\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5005 - val_loss: 0.4961\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4994 - val_loss: 0.4890\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.4894 - val_loss: 0.4922\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.4837 - val_loss: 0.4900\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.4803 - val_loss: 0.4952\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.4732 - val_loss: 0.4893\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.4647 - val_loss: 0.4867\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4530 - val_loss: 0.4583\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.4160 - val_loss: 0.4115\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3733 - val_loss: 0.3614\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3425 - val_loss: 0.3291\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3234 - val_loss: 0.3153\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3127 - val_loss: 0.3056\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3042 - val_loss: 0.3049\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2958 - val_loss: 0.3026\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2915 - val_loss: 0.2886\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2818 - val_loss: 0.2837\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2817 - val_loss: 0.2911\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2763 - val_loss: 0.2819\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2701 - val_loss: 0.2820\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2653 - val_loss: 0.2817\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2614 - val_loss: 0.2787\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2609 - val_loss: 0.2740\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2501 - val_loss: 0.2697\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2481 - val_loss: 0.2629\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2412 - val_loss: 0.2608\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2354 - val_loss: 0.2496\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2274 - val_loss: 0.2453\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2180 - val_loss: 0.2355\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.2074 - val_loss: 0.2224\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.1946 - val_loss: 0.2019\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.1834 - val_loss: 0.1970\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1736 - val_loss: 0.1808\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1640 - val_loss: 0.1632\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1558 - val_loss: 0.1598\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1541 - val_loss: 0.1600\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1474 - val_loss: 0.1550\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1453 - val_loss: 0.1490\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1411 - val_loss: 0.1503\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1408 - val_loss: 0.1428\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1349 - val_loss: 0.1427\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1324 - val_loss: 0.1429\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1290 - val_loss: 0.1459\n",
      "MSE over 1000 samples on the run 2 : 0.1446 \n",
      "Mean of the MSE on 3 independant runs 0.1789 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_deep_1(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    We see here one of the risks of Early Stopping when the model stops a little too early (Second run where the model stops at 27 epoches) and has not been trained enough to be able to perform well during the testing phase. **But the model with and without FC layers have about the same performance in terms of MSE.** \n",
    "    </font>\n",
    "    \n",
    "> <font color='blue'>\n",
    "    Now, let's not use the Early Stopping to see its influence on FC layers.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 2s 203us/step - loss: 4.0769 - val_loss: 0.8565\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.7638 - val_loss: 0.7868\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.7341 - val_loss: 0.7717\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.7133 - val_loss: 0.7352\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.6770 - val_loss: 0.7145\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6292 - val_loss: 0.6839\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.6102 - val_loss: 0.6544\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.5979 - val_loss: 0.6485\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.5853 - val_loss: 0.6588\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.5730 - val_loss: 0.6611\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.5687 - val_loss: 0.6620\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.5632 - val_loss: 0.6538\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.5576 - val_loss: 0.6546\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.5529 - val_loss: 0.6575\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.5480 - val_loss: 0.6542\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.5427 - val_loss: 0.6486\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.5389 - val_loss: 0.6385\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.5316 - val_loss: 0.6271\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.5036 - val_loss: 0.5909\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.4615 - val_loss: 0.5137\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.4108 - val_loss: 0.4471\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3776 - val_loss: 0.4236\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.3573 - val_loss: 0.4025\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.3429 - val_loss: 0.3910\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3379 - val_loss: 0.3769\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3236 - val_loss: 0.3785\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3182 - val_loss: 0.3723\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3187 - val_loss: 0.3709\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.3079 - val_loss: 0.3581\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3066 - val_loss: 0.3554\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.2960 - val_loss: 0.3629\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.2962 - val_loss: 0.3578\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.2895 - val_loss: 0.3438\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 20us/step - loss: 0.2829 - val_loss: 0.3300\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.2756 - val_loss: 0.3262\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.2592 - val_loss: 0.3035\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2385 - val_loss: 0.2555\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.2141 - val_loss: 0.2254\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1963 - val_loss: 0.1962\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1874 - val_loss: 0.1881\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1791 - val_loss: 0.1809\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1727 - val_loss: 0.1727\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.1681 - val_loss: 0.1707\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.1633 - val_loss: 0.1783\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.1586 - val_loss: 0.1590\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1598 - val_loss: 0.1702\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1528 - val_loss: 0.1589\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1545 - val_loss: 0.1622\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1463 - val_loss: 0.1572\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1415 - val_loss: 0.1522\n",
      "MSE over 1000 samples on the run 0 : 0.1285 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 2s 172us/step - loss: 3.2175 - val_loss: 0.7255\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6894 - val_loss: 0.6844\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.6633 - val_loss: 0.6506\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.6226 - val_loss: 0.5771\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.5630 - val_loss: 0.5309\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5380 - val_loss: 0.5145\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.5305 - val_loss: 0.5154\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5165 - val_loss: 0.5039\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.5072 - val_loss: 0.5009\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.4979 - val_loss: 0.5042\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.4965 - val_loss: 0.4889\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.4830 - val_loss: 0.4878\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.4735 - val_loss: 0.4668\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.4336 - val_loss: 0.4160\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.3937 - val_loss: 0.3803\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3627 - val_loss: 0.3587\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.3425 - val_loss: 0.3496\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3333 - val_loss: 0.3505\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 24us/step - loss: 0.3237 - val_loss: 0.3414\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3164 - val_loss: 0.3298\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3071 - val_loss: 0.3329\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3017 - val_loss: 0.3312\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.2939 - val_loss: 0.3277\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2891 - val_loss: 0.3194\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.2829 - val_loss: 0.3180\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.2770 - val_loss: 0.3018\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.2650 - val_loss: 0.2971\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.2561 - val_loss: 0.2858\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.2423 - val_loss: 0.2613\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 20us/step - loss: 0.2228 - val_loss: 0.2395\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.1995 - val_loss: 0.2121\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 23us/step - loss: 0.1810 - val_loss: 0.1888\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.1666 - val_loss: 0.1794\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 22us/step - loss: 0.1599 - val_loss: 0.1686\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.1550 - val_loss: 0.1609\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 21us/step - loss: 0.1489 - val_loss: 0.1565\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1457 - val_loss: 0.1557\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.1364 - val_loss: 0.1579\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1370 - val_loss: 0.1508\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.1333 - val_loss: 0.1495\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1325 - val_loss: 0.1513\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1300 - val_loss: 0.1540\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1299 - val_loss: 0.1496\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1265 - val_loss: 0.1516\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.1243 - val_loss: 0.1488\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1247 - val_loss: 0.1473\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1219 - val_loss: 0.1432\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.1228 - val_loss: 0.1484\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 1s 67us/step - loss: 0.1181 - val_loss: 0.1397\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1169 - val_loss: 0.1434\n",
      "MSE over 1000 samples on the run 1 : 0.1289 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 2s 175us/step - loss: 4.2500 - val_loss: 0.9052\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.7795 - val_loss: 0.8168\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.7594 - val_loss: 0.8170\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.7341 - val_loss: 0.7918\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.6967 - val_loss: 0.7476\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.6555 - val_loss: 0.7155\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.6326 - val_loss: 0.6980\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.6195 - val_loss: 0.7039\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.6142 - val_loss: 0.6944\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.6043 - val_loss: 0.7021\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5928 - val_loss: 0.6830\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5874 - val_loss: 0.6923\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5764 - val_loss: 0.6771\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5684 - val_loss: 0.6568\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5381 - val_loss: 0.6223\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.4886 - val_loss: 0.5211\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.4377 - val_loss: 0.4620\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4030 - val_loss: 0.4324\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3834 - val_loss: 0.4078\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3660 - val_loss: 0.4181\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3574 - val_loss: 0.3943\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3467 - val_loss: 0.3828\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3430 - val_loss: 0.3707\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3289 - val_loss: 0.3577\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.3202 - val_loss: 0.3618\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.3028 - val_loss: 0.3331\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.2773 - val_loss: 0.2896\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.2527 - val_loss: 0.2518\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.2193 - val_loss: 0.2223\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1955 - val_loss: 0.1900\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1805 - val_loss: 0.1829\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1756 - val_loss: 0.1815\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1716 - val_loss: 0.1672\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1664 - val_loss: 0.1720\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1595 - val_loss: 0.1653\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1587 - val_loss: 0.1596\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1551 - val_loss: 0.1570\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1553 - val_loss: 0.1570\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1468 - val_loss: 0.1602\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1489 - val_loss: 0.1557\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1526 - val_loss: 0.1519\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1450 - val_loss: 0.1485\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1437 - val_loss: 0.1613\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1425 - val_loss: 0.1515\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1408 - val_loss: 0.1524\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1416 - val_loss: 0.1499\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 25us/step - loss: 0.1385 - val_loss: 0.1507\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1379 - val_loss: 0.1487\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1365 - val_loss: 0.1475\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1365 - val_loss: 0.1487\n",
      "MSE over 1000 samples on the run 2 : 0.1419 \n",
      "Mean of the MSE on 3 independant runs 0.1331 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_deep_1(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    **According to the results above, we see that when we are using FC layers, it is best not to use the Early Stopping (ES) in order to allow the model learn more even though there may be a risk of overfitting.** Indeed, on average, we obtain a MSE of 0.13 without ES and a MSE of 0.18 with ES.\n",
    "    </font>\n",
    "    \n",
    "> <font color='blue'>\n",
    "    We will try now to make a more deeper model by adding one another FC layer.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5) Matrix factorization approach with embeddings and non linearities (2 FC layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_system_deep_2(train_x, train_y, embedding_size, nb_users, nb_items) :    \n",
    "    \n",
    "    user_id_input = Input(shape=[1],name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "    embedding_size = embedding_size\n",
    "    user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "    item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "    input_vecs = Concatenate()([user_vecs, item_vecs])\n",
    "    x = Dense(64, activation='relu')(input_vecs)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    y = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y)\n",
    "    model.compile(optimizer='adam', loss='MSE')\n",
    "    history = model.fit([train_ratings[\"user_id\"], train_ratings[\"item_id\"]], train_ratings[\"rating\"],\n",
    "                        batch_size=64, epochs=50, validation_split=0.1,\n",
    "                        shuffle=True)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 2s 184us/step - loss: 3.6951 - val_loss: 0.7711\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.8994 - val_loss: 0.6979\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.8127 - val_loss: 0.6448\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.7720 - val_loss: 0.6269\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.7452 - val_loss: 0.6064\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.7115 - val_loss: 0.6246\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6813 - val_loss: 0.5957\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6693 - val_loss: 0.6048\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6563 - val_loss: 0.5975\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6359 - val_loss: 0.5845\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6134 - val_loss: 0.5742\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6017 - val_loss: 0.5603\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.5765 - val_loss: 0.5274\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.5416 - val_loss: 0.4890\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.4979 - val_loss: 0.4631\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.4592 - val_loss: 0.3874\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.4280 - val_loss: 0.3532\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.4071 - val_loss: 0.3290\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3863 - val_loss: 0.3277\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.3552 - val_loss: 0.2890\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3527 - val_loss: 0.2882\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3377 - val_loss: 0.2834\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3203 - val_loss: 0.2609\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.3006 - val_loss: 0.2520\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2881 - val_loss: 0.2419\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2789 - val_loss: 0.2506\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2668 - val_loss: 0.2288\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2603 - val_loss: 0.2366\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2392 - val_loss: 0.2097\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2297 - val_loss: 0.1995\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2284 - val_loss: 0.1916\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2137 - val_loss: 0.1921\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2092 - val_loss: 0.1986\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.2076 - val_loss: 0.1913\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1948 - val_loss: 0.1841\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1896 - val_loss: 0.1764\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1862 - val_loss: 0.1909\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1846 - val_loss: 0.1791\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1841 - val_loss: 0.2000\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1765 - val_loss: 0.1822\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1800 - val_loss: 0.1715\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1691 - val_loss: 0.1761\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1710 - val_loss: 0.1811\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1648 - val_loss: 0.1766\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1621 - val_loss: 0.1924\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1648 - val_loss: 0.1717\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 30us/step - loss: 0.1583 - val_loss: 0.1884\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1578 - val_loss: 0.1789\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1557 - val_loss: 0.1846\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1578 - val_loss: 0.1842\n",
      "MSE over 1000 samples on the run 0 : 0.1550 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 2s 195us/step - loss: 3.6265 - val_loss: 0.7270\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.8889 - val_loss: 0.6695\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.7977 - val_loss: 0.6466\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.7508 - val_loss: 0.6318\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.7317 - val_loss: 0.6222\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.7060 - val_loss: 0.6236\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 31us/step - loss: 0.6884 - val_loss: 0.6068\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6699 - val_loss: 0.6081\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6444 - val_loss: 0.6173\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.6297 - val_loss: 0.6180\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6023 - val_loss: 0.5927\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5928 - val_loss: 0.5872\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.5645 - val_loss: 0.5297\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.5208 - val_loss: 0.4851\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4840 - val_loss: 0.4496\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4397 - val_loss: 0.4080\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3951 - val_loss: 0.3487\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3670 - val_loss: 0.3185\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3367 - val_loss: 0.2721\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2972 - val_loss: 0.2409\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2728 - val_loss: 0.2222\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2552 - val_loss: 0.2172\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2340 - val_loss: 0.1940\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2331 - val_loss: 0.1858\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2158 - val_loss: 0.1755\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2016 - val_loss: 0.1687\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1997 - val_loss: 0.1704\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1918 - val_loss: 0.1618\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1819 - val_loss: 0.1620\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1853 - val_loss: 0.1684\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1779 - val_loss: 0.1607\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1761 - val_loss: 0.1647\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1677 - val_loss: 0.1605\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1663 - val_loss: 0.1689\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1659 - val_loss: 0.1617\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1618 - val_loss: 0.1619\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1502 - val_loss: 0.1568\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1500 - val_loss: 0.1727\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1531 - val_loss: 0.1605\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1481 - val_loss: 0.1588\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1497 - val_loss: 0.1560\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1440 - val_loss: 0.1624\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1385 - val_loss: 0.1604\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1410 - val_loss: 0.1597\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1354 - val_loss: 0.1702\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1390 - val_loss: 0.1605\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1365 - val_loss: 0.1538\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.1369 - val_loss: 0.1560\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1359 - val_loss: 0.1558\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1292 - val_loss: 0.1573\n",
      "MSE over 1000 samples on the run 1 : 0.1406 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 2s 201us/step - loss: 3.7275 - val_loss: 0.6933\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.8492 - val_loss: 0.6539\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.7583 - val_loss: 0.5649\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.7082 - val_loss: 0.5763\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6693 - val_loss: 0.5750\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6466 - val_loss: 0.5420\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6258 - val_loss: 0.5443\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.6058 - val_loss: 0.5316\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 26us/step - loss: 0.5879 - val_loss: 0.5380\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5714 - val_loss: 0.5206\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5581 - val_loss: 0.5203\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5402 - val_loss: 0.4817\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.5016 - val_loss: 0.4422\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4548 - val_loss: 0.3703\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.4097 - val_loss: 0.3255\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3854 - val_loss: 0.3085\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3565 - val_loss: 0.2789\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3329 - val_loss: 0.2680\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.3136 - val_loss: 0.2411\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2976 - val_loss: 0.2198\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2829 - val_loss: 0.2003\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2586 - val_loss: 0.2033\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2474 - val_loss: 0.1846\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2421 - val_loss: 0.1725\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.2230 - val_loss: 0.1654\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2195 - val_loss: 0.1627\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.2087 - val_loss: 0.1556\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.2021 - val_loss: 0.1553\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1995 - val_loss: 0.1542\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1914 - val_loss: 0.1538\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1863 - val_loss: 0.1560\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1820 - val_loss: 0.1561\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1803 - val_loss: 0.1575\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1732 - val_loss: 0.1561\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1678 - val_loss: 0.1461\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1691 - val_loss: 0.1437\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1695 - val_loss: 0.1476\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1635 - val_loss: 0.1422\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1560 - val_loss: 0.1343\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1576 - val_loss: 0.1449\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 29us/step - loss: 0.1556 - val_loss: 0.1514\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1486 - val_loss: 0.1413\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1495 - val_loss: 0.1499\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1441 - val_loss: 0.1435\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1469 - val_loss: 0.1417\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1438 - val_loss: 0.1345\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1381 - val_loss: 0.1368\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1383 - val_loss: 0.1441\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 28us/step - loss: 0.1349 - val_loss: 0.1547\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 27us/step - loss: 0.1371 - val_loss: 0.1329\n",
      "MSE over 1000 samples on the run 2 : 0.1439 \n",
      "Mean of the MSE on 3 independant runs 0.1465 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_deep_2(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    Let's try to decrease the coefficient of drop out from 0.5 to 0.3 in the first FC layer to see whether it is improving the MSE.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_system_deep_2(train_x, train_y, embedding_size, nb_users, nb_items) :    \n",
    "    \n",
    "    user_id_input = Input(shape=[1],name='user')\n",
    "    item_id_input = Input(shape=[1], name='item')\n",
    "    embedding_size = embedding_size\n",
    "    user_embedding = Embedding(output_dim=embedding_size, input_dim=nb_users + 1,\n",
    "                           input_length=1, name='user_embedding')(user_id_input)\n",
    "    item_embedding = Embedding(output_dim=embedding_size, input_dim=nb_items + 1,\n",
    "                           input_length=1, name='item_embedding')(item_id_input)\n",
    "    user_vecs = Flatten()(user_embedding)\n",
    "    item_vecs = Flatten()(item_embedding)\n",
    "    input_vecs = Concatenate()([user_vecs, item_vecs])\n",
    "    x = Dense(64, activation='relu')(input_vecs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(32, activation='relu')(x)\n",
    "    y = Dense(1)(x)\n",
    "\n",
    "    model = Model(inputs=[user_id_input, item_id_input], outputs=y)\n",
    "    model.compile(optimizer='adam', loss='MSE')\n",
    "    history = model.fit([train_ratings[\"user_id\"], train_ratings[\"item_id\"]], train_ratings[\"rating\"],\n",
    "                        batch_size=64, epochs=50, validation_split=0.1,\n",
    "                        shuffle=True)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 4s 445us/step - loss: 3.1654 - val_loss: 0.6705\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.7514 - val_loss: 0.6387\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.6755 - val_loss: 0.5719\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.6547 - val_loss: 0.5631\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 1s 68us/step - loss: 0.6365 - val_loss: 0.5644\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.6176 - val_loss: 0.5680\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.6066 - val_loss: 0.5362\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.5963 - val_loss: 0.5434\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.5812 - val_loss: 0.5435\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.5497 - val_loss: 0.5157\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.5067 - val_loss: 0.4528\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.4565 - val_loss: 0.4160\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.4266 - val_loss: 0.3776\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.3720 - val_loss: 0.2956\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.3096 - val_loss: 0.2425\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.2813 - val_loss: 0.2088\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.2568 - val_loss: 0.1984\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.2533 - val_loss: 0.1975\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.2396 - val_loss: 0.1786\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.2336 - val_loss: 0.1822\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.2226 - val_loss: 0.1863\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.2092 - val_loss: 0.1742\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.2055 - val_loss: 0.1637\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1992 - val_loss: 0.1630\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1840 - val_loss: 0.1629\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.1853 - val_loss: 0.1607\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1789 - val_loss: 0.1510\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.1781 - val_loss: 0.1491\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1649 - val_loss: 0.1489\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1661 - val_loss: 0.1428\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1624 - val_loss: 0.1439\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1548 - val_loss: 0.1452\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.1503 - val_loss: 0.1403\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1481 - val_loss: 0.1434\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1459 - val_loss: 0.1404\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1368 - val_loss: 0.1389\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1332 - val_loss: 0.1429\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1326 - val_loss: 0.1418\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1308 - val_loss: 0.1383\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.1251 - val_loss: 0.1340\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1201 - val_loss: 0.1276\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1200 - val_loss: 0.1456\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.1179 - val_loss: 0.1283\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.1154 - val_loss: 0.1420\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.1124 - val_loss: 0.1282\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1134 - val_loss: 0.1229\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1096 - val_loss: 0.1251\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1066 - val_loss: 0.1262\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1052 - val_loss: 0.1307\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1029 - val_loss: 0.1268\n",
      "MSE over 1000 samples on the run 0 : 0.1321 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 4s 391us/step - loss: 4.2319 - val_loss: 0.6503\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.7740 - val_loss: 0.6406\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.7113 - val_loss: 0.5695\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.6773 - val_loss: 0.5570\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.6463 - val_loss: 0.5316\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.6353 - val_loss: 0.5456\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.6257 - val_loss: 0.5308\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.6112 - val_loss: 0.5387\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.6106 - val_loss: 0.5258\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.5978 - val_loss: 0.5457\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.5853 - val_loss: 0.5332\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.5819 - val_loss: 0.5407\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.5732 - val_loss: 0.5243\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.5621 - val_loss: 0.4879\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.5077 - val_loss: 0.4622\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 35us/step - loss: 0.4673 - val_loss: 0.3977\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.4248 - val_loss: 0.3654\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.3913 - val_loss: 0.3472\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.3724 - val_loss: 0.3299\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.3543 - val_loss: 0.3251\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.3368 - val_loss: 0.3010\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.3234 - val_loss: 0.2974\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.3100 - val_loss: 0.2802\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.2888 - val_loss: 0.2601\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.2672 - val_loss: 0.2424\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.2472 - val_loss: 0.2239\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.2331 - val_loss: 0.1994\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.2083 - val_loss: 0.1969\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1996 - val_loss: 0.1743\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.1886 - val_loss: 0.1734\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1856 - val_loss: 0.1638\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1732 - val_loss: 0.1661\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1727 - val_loss: 0.1649\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.1661 - val_loss: 0.1591\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1658 - val_loss: 0.1610\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1531 - val_loss: 0.1497\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1503 - val_loss: 0.1559\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1448 - val_loss: 0.1585\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1409 - val_loss: 0.1520\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1409 - val_loss: 0.1493\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1371 - val_loss: 0.1579\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1297 - val_loss: 0.1569\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.1277 - val_loss: 0.1528\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1242 - val_loss: 0.1440\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.1226 - val_loss: 0.1388\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 33us/step - loss: 0.1200 - val_loss: 0.1437\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1156 - val_loss: 0.1453\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 32us/step - loss: 0.1165 - val_loss: 0.1462\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1147 - val_loss: 0.1402\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 34us/step - loss: 0.1106 - val_loss: 0.1437\n",
      "MSE over 1000 samples on the run 1 : 0.1062 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 3s 386us/step - loss: 3.0751 - val_loss: 0.6326\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.7183 - val_loss: 0.6095\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.6567 - val_loss: 0.5561\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.6345 - val_loss: 0.5682\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.6188 - val_loss: 0.5517\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.6013 - val_loss: 0.5530\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.5937 - val_loss: 0.5491\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.5837 - val_loss: 0.5292\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.5642 - val_loss: 0.5491\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.5513 - val_loss: 0.5198\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.5279 - val_loss: 0.4869\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.4588 - val_loss: 0.4154\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.4030 - val_loss: 0.3648\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.3638 - val_loss: 0.3292\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.3242 - val_loss: 0.2735\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.2705 - val_loss: 0.2226\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.2572 - val_loss: 0.1931\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.2351 - val_loss: 0.1842\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.2228 - val_loss: 0.1799\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.2212 - val_loss: 0.1757\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.2090 - val_loss: 0.1620\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.2022 - val_loss: 0.1677\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1886 - val_loss: 0.1699\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1916 - val_loss: 0.1584\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1926 - val_loss: 0.1657\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1810 - val_loss: 0.1584\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1782 - val_loss: 0.1638\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1717 - val_loss: 0.1536\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1656 - val_loss: 0.1588\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1602 - val_loss: 0.1571\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1562 - val_loss: 0.1541\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1535 - val_loss: 0.1474\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1545 - val_loss: 0.1542\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.1431 - val_loss: 0.1467\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1446 - val_loss: 0.1500\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1385 - val_loss: 0.1521\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1366 - val_loss: 0.1573\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1354 - val_loss: 0.1452\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1342 - val_loss: 0.1573\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1281 - val_loss: 0.1531\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1299 - val_loss: 0.1473\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1241 - val_loss: 0.1482\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1234 - val_loss: 0.1531\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1192 - val_loss: 0.1462\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1180 - val_loss: 0.1516\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1164 - val_loss: 0.1458\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1116 - val_loss: 0.1491\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1106 - val_loss: 0.1496\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1099 - val_loss: 0.1516\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1080 - val_loss: 0.1550\n",
      "MSE over 1000 samples on the run 2 : 0.1049 \n",
      "Mean of the MSE on 3 independant runs 0.1144 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_deep_2(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    The performance is improved in average when we are decreasing a little bit the Drop out from 0.5 to 0.3, leaving more active neurons !\n",
    "    </font>\n",
    "    \n",
    "> <font color='blue'>\n",
    "    Let's now test online learning by fiting only the new prediction each time and see if it improves the performance of the recommendation system.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 5s 502us/step - loss: 3.8251 - val_loss: 0.8207\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.8362 - val_loss: 0.7353\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.7650 - val_loss: 0.6715\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.7068 - val_loss: 0.6406\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.6869 - val_loss: 0.6298\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.6776 - val_loss: 0.6302\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.6660 - val_loss: 0.6393\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.6463 - val_loss: 0.6198\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.6398 - val_loss: 0.6241\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.6286 - val_loss: 0.6294\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.6163 - val_loss: 0.6004\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.6144 - val_loss: 0.5925\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.6056 - val_loss: 0.6158\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.5887 - val_loss: 0.6080\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 1s 69us/step - loss: 0.5680 - val_loss: 0.5554\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.5073 - val_loss: 0.4620\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 1s 67us/step - loss: 0.4583 - val_loss: 0.4342\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.4225 - val_loss: 0.4135\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.4040 - val_loss: 0.3985\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 1s 71us/step - loss: 0.3799 - val_loss: 0.3796\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.3651 - val_loss: 0.3774\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.3516 - val_loss: 0.3557\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.3410 - val_loss: 0.3390\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.3255 - val_loss: 0.3280\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.3085 - val_loss: 0.3053\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.2796 - val_loss: 0.2768\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.2586 - val_loss: 0.2501\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.2429 - val_loss: 0.2417\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.2290 - val_loss: 0.2222\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.2146 - val_loss: 0.2043\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.2068 - val_loss: 0.1905\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1989 - val_loss: 0.1860\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1929 - val_loss: 0.1858\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1803 - val_loss: 0.1852\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1728 - val_loss: 0.1774\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1703 - val_loss: 0.1727\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1643 - val_loss: 0.1790\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1585 - val_loss: 0.1802\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1579 - val_loss: 0.1697\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1519 - val_loss: 0.1659\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1493 - val_loss: 0.1681\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1462 - val_loss: 0.1633\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1420 - val_loss: 0.1665\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1387 - val_loss: 0.1698\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1331 - val_loss: 0.1620\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1318 - val_loss: 0.1603\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1293 - val_loss: 0.1592\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.1258 - val_loss: 0.1574\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1279 - val_loss: 0.1615\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1216 - val_loss: 0.1616\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0298\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0363\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0082\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1778\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0713\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0124\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0774\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7280\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0312\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1965\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0095\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0873\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0660\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1952\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3778\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.3792e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.8131\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0544\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1067\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0037\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0012\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3284\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6137e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2431\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0286\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0788\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7862\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.7640\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2416\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0409\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0563\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3768\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6904\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4758\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5705\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0987\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2149\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3383\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0266\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8506\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5404\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2368\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3284\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7968\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7236\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1386\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4906\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1295\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0807\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5030\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0020e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0121\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0570\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6253\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0384\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1258\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4687\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6385\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6737\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0922\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7402\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0159\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.6106\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7683e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.0882\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4767\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0243\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9788\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0557\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0090\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1808\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0748\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9061\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3335\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0014\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2520\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2483\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4763\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0082\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2346\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5778\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.3137\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0428\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1285\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0091\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0548\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0025\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3953\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0010\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5451\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.9615\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3992\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0554\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0046\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6092\n",
      "MSE over 1000 samples on the run 0 : 0.3633 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 4s 475us/step - loss: 2.9931 - val_loss: 0.6787\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.7563 - val_loss: 0.6121\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.6787 - val_loss: 0.5496\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.6364 - val_loss: 0.5580\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.6251 - val_loss: 0.5365\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.6128 - val_loss: 0.5419\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.6006 - val_loss: 0.5315\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.5885 - val_loss: 0.5327\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 36us/step - loss: 0.5693 - val_loss: 0.5255\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.5634 - val_loss: 0.5218\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.5449 - val_loss: 0.4981\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.5231 - val_loss: 0.4602\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.4687 - val_loss: 0.4095\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.4286 - val_loss: 0.3734\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.3828 - val_loss: 0.3263\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.3532 - val_loss: 0.2992\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.3176 - val_loss: 0.2716\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.2915 - val_loss: 0.2441\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.2720 - val_loss: 0.2155\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.2435 - val_loss: 0.1779\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.2207 - val_loss: 0.1657\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.2109 - val_loss: 0.1609\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1987 - val_loss: 0.1673\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1906 - val_loss: 0.1496\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 37us/step - loss: 0.1883 - val_loss: 0.1479\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1795 - val_loss: 0.1476\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1711 - val_loss: 0.1485\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1632 - val_loss: 0.1379\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.1616 - val_loss: 0.1394\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1572 - val_loss: 0.1363\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.1527 - val_loss: 0.1310\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.1517 - val_loss: 0.1398\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.1446 - val_loss: 0.1248\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 1s 73us/step - loss: 0.1481 - val_loss: 0.1287\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.1404 - val_loss: 0.1321\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1345 - val_loss: 0.1286\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1300 - val_loss: 0.1257\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1316 - val_loss: 0.1286\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1222 - val_loss: 0.1250\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1234 - val_loss: 0.1329\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1208 - val_loss: 0.1259\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1174 - val_loss: 0.1323\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1146 - val_loss: 0.1299\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1085 - val_loss: 0.1305\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1144 - val_loss: 0.1270\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1116 - val_loss: 0.1284\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1063 - val_loss: 0.1242\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1049 - val_loss: 0.1246\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1022 - val_loss: 0.1236\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.1028 - val_loss: 0.1275\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1142\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0098\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0151\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0196\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5617\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2798\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0155\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5473\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9301e-05\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1574\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1618\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0940\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3831\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6335\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.5775e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6323\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0780\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0422\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0076\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4445\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0050\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3958\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.6879e-05\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3166\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0035\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0077\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0033\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0790\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0123\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0343\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2092\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2429\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1881\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0812\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5454e-05\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9669\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4568\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0075\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4275\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1090\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1120\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1916\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3272\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1697\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4335\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4883\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0046\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1694\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9636\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7823\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1170\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8055\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.0105\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.4701e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3280\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4282\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.9157\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1314\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7965\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0355\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0678\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.8733\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7212\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5487\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.8649\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3704\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0657\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0271\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4278\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9490\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0195\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.6925\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0476\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0364\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3184\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0076\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.7555\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0267\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0141\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.8383\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1180\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0061\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1449\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3188\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5222\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.9838\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9833\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1220\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1961\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2417\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3253\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.5184e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0464\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0076\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.0733\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5730\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4464\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.6923\n",
      "MSE over 1000 samples on the run 1 : 0.4168 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 6s 648us/step - loss: 2.9224 - val_loss: 0.6534\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.7063 - val_loss: 0.5929\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.6359 - val_loss: 0.5589\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.6178 - val_loss: 0.5450\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.5907 - val_loss: 0.5295\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.5770 - val_loss: 0.5222\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.5445 - val_loss: 0.4943\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.5019 - val_loss: 0.4429\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.4454 - val_loss: 0.3769\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.3814 - val_loss: 0.3036\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.3082 - val_loss: 0.2488\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.2806 - val_loss: 0.2053\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.2537 - val_loss: 0.1949\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.2381 - val_loss: 0.1844\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.2211 - val_loss: 0.1843\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.2095 - val_loss: 0.1766\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.2054 - val_loss: 0.1720\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.2049 - val_loss: 0.1666\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1974 - val_loss: 0.1740\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1890 - val_loss: 0.1679\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.1808 - val_loss: 0.1554\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 55us/step - loss: 0.1788 - val_loss: 0.1564\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.1721 - val_loss: 0.1597\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 39us/step - loss: 0.1669 - val_loss: 0.1549\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1653 - val_loss: 0.1546\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 38us/step - loss: 0.1651 - val_loss: 0.1554\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1569 - val_loss: 0.1511\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.1582 - val_loss: 0.1524\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1536 - val_loss: 0.1505\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.1448 - val_loss: 0.1563\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.1399 - val_loss: 0.1509\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.1456 - val_loss: 0.1504\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.1402 - val_loss: 0.1443\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.1390 - val_loss: 0.1488\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.1327 - val_loss: 0.1434\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 1s 61us/step - loss: 0.1300 - val_loss: 0.1368\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.1286 - val_loss: 0.1426\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.1259 - val_loss: 0.1417\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1238 - val_loss: 0.1465\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1286 - val_loss: 0.1447\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1183 - val_loss: 0.1467\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1181 - val_loss: 0.1489\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1163 - val_loss: 0.1443\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1175 - val_loss: 0.1403\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1146 - val_loss: 0.1375\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.1121 - val_loss: 0.1399\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1117 - val_loss: 0.1438\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.1093 - val_loss: 0.1432\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1051 - val_loss: 0.1438\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1044 - val_loss: 0.1395\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1905\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0128\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.4681e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1677\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0057\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1797\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0158\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1747\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1367\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1203\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0474\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5155\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0410\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9362\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0111\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.9539\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0214\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0137\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1409\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1158\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.5021e-06\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2825e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0740\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1267\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0027\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5554\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0310\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2325\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1134\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1538\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5008\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1982\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3312\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0133\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3317\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3158\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2482\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0034\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0287\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6159\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8869\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0799\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2581\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1297\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1684\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2709\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9306\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1059\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0421\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1970\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0120\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0104\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2393\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0233\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0681\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 2.2003\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2066\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0040\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5904\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1045\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0734\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.7521\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2569\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0496\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7462\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4880\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7036\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0020\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0419\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7118e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1464\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3474\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0619\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.5334e-07\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0434\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4724\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1287\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0348\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.5606e-04\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4187\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0442\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2654\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1228\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0216\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.3407\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0175\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2827\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.9139\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1047\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0033\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9636\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0705\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0648\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4129\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4040\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.9562\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0587\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6688\n",
      "MSE over 1000 samples on the run 2 : 0.3626 \n",
      "Mean of the MSE on 3 independant runs 0.3809 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_deep_2(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "\n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        model.fit([[next_user], [next_item]], [rating])\n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    As we can see, the performance has really declined. Maybe we should not only fit after each new prediction but should we fit many more new predictions at a time, this means that we store the predictions in a liste and after about 10 or more predictions, we fit the model. We will see if it is improving the model.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size : 50\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 5s 586us/step - loss: 3.3669 - val_loss: 0.6479\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.7354 - val_loss: 0.6039\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 1s 68us/step - loss: 0.6849 - val_loss: 0.5626\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.6393 - val_loss: 0.5422\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.6242 - val_loss: 0.5573\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.6042 - val_loss: 0.5400\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 1s 71us/step - loss: 0.5990 - val_loss: 0.5397\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.5784 - val_loss: 0.5305\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.5481 - val_loss: 0.4903\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.5037 - val_loss: 0.4000\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 1s 70us/step - loss: 0.4217 - val_loss: 0.3378\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.3932 - val_loss: 0.3308\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 1s 81us/step - loss: 0.3739 - val_loss: 0.3080\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 1s 80us/step - loss: 0.3573 - val_loss: 0.3167\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.3423 - val_loss: 0.3071\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 1s 83us/step - loss: 0.3388 - val_loss: 0.3107\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.3209 - val_loss: 0.3037\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 1s 61us/step - loss: 0.3081 - val_loss: 0.2802\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.2916 - val_loss: 0.2691\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.2591 - val_loss: 0.2273\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.2369 - val_loss: 0.1967\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.2184 - val_loss: 0.1798\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 40us/step - loss: 0.2073 - val_loss: 0.1827\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1929 - val_loss: 0.1691\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1928 - val_loss: 0.1604\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1862 - val_loss: 0.1707\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 1s 70us/step - loss: 0.1769 - val_loss: 0.1572\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1740 - val_loss: 0.1572\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1682 - val_loss: 0.1624\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 1s 71us/step - loss: 0.1614 - val_loss: 0.1539\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.1591 - val_loss: 0.1484\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 1s 61us/step - loss: 0.1543 - val_loss: 0.1526\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.1508 - val_loss: 0.1488\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.1443 - val_loss: 0.1587\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.1453 - val_loss: 0.1439\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1403 - val_loss: 0.1473\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.1358 - val_loss: 0.1453\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.1335 - val_loss: 0.1385\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1247 - val_loss: 0.1353\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 1s 62us/step - loss: 0.1249 - val_loss: 0.1390\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.1261 - val_loss: 0.1424\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 1s 69us/step - loss: 0.1220 - val_loss: 0.1454\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 1s 78us/step - loss: 0.1182 - val_loss: 0.1388\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 1s 72us/step - loss: 0.1121 - val_loss: 0.1407\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.1148 - val_loss: 0.1484\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 1s 75us/step - loss: 0.1079 - val_loss: 0.1394\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 1s 81us/step - loss: 0.1080 - val_loss: 0.1391\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.1075 - val_loss: 0.1383\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 1s 77us/step - loss: 0.1039 - val_loss: 0.1409\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 1s 67us/step - loss: 0.1026 - val_loss: 0.1351\n",
      "MSE over 1000 samples on the run 0 : 0.1813 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 5s 574us/step - loss: 3.0498 - val_loss: 0.7597\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.7959 - val_loss: 0.6989\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.7387 - val_loss: 0.6368\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.7013 - val_loss: 0.6090\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.6828 - val_loss: 0.6080\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.6667 - val_loss: 0.6207\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.6470 - val_loss: 0.5979\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.6185 - val_loss: 0.5908\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.5813 - val_loss: 0.5035\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 1s 61us/step - loss: 0.4640 - val_loss: 0.3570\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 1s 66us/step - loss: 0.3726 - val_loss: 0.2804\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 1s 60us/step - loss: 0.3172 - val_loss: 0.2319\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.2873 - val_loss: 0.2168\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.2616 - val_loss: 0.1997\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.2498 - val_loss: 0.1839\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.2366 - val_loss: 0.1870\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.2303 - val_loss: 0.1747\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 1s 58us/step - loss: 0.2257 - val_loss: 0.1772\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.2186 - val_loss: 0.1688\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.2067 - val_loss: 0.1672\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.2032 - val_loss: 0.1609\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.2049 - val_loss: 0.1596\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1959 - val_loss: 0.1608\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.2014 - val_loss: 0.1674\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1922 - val_loss: 0.1669\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.1898 - val_loss: 0.1561\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1794 - val_loss: 0.1576\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.1754 - val_loss: 0.1564\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1734 - val_loss: 0.1557\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 56us/step - loss: 0.1674 - val_loss: 0.1587\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.1614 - val_loss: 0.1552\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.1581 - val_loss: 0.1595\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1538 - val_loss: 0.1610\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1522 - val_loss: 0.1586\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1490 - val_loss: 0.1598\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.1427 - val_loss: 0.1532\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1441 - val_loss: 0.1581\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 1s 65us/step - loss: 0.1396 - val_loss: 0.1523\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.1337 - val_loss: 0.1575\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 1s 79us/step - loss: 0.1365 - val_loss: 0.1520\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.1307 - val_loss: 0.1521\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 1s 69us/step - loss: 0.1297 - val_loss: 0.1565\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 1s 63us/step - loss: 0.1243 - val_loss: 0.1538\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1269 - val_loss: 0.1452\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 1s 66us/step - loss: 0.1197 - val_loss: 0.1484\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 1s 74us/step - loss: 0.1220 - val_loss: 0.1575\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 1s 94us/step - loss: 0.1196 - val_loss: 0.1525\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 1s 116us/step - loss: 0.1141 - val_loss: 0.1471\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 1s 56us/step - loss: 0.1134 - val_loss: 0.1480\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.1156 - val_loss: 0.1527\n",
      "MSE over 1000 samples on the run 1 : 0.1283 \n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 6s 695us/step - loss: 3.0586 - val_loss: 0.6463\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.6902 - val_loss: 0.5947\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 0s 51us/step - loss: 0.6410 - val_loss: 0.5390\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.6123 - val_loss: 0.5207\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.5995 - val_loss: 0.5448\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.5763 - val_loss: 0.5226\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.5664 - val_loss: 0.5060\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.5507 - val_loss: 0.5132\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.5373 - val_loss: 0.4949\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.5069 - val_loss: 0.4422\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.4541 - val_loss: 0.3690\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.4030 - val_loss: 0.3369\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.3760 - val_loss: 0.3213\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.3624 - val_loss: 0.3013\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.3519 - val_loss: 0.3028\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.3363 - val_loss: 0.3036\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.3302 - val_loss: 0.2815\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.2960 - val_loss: 0.2476\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.2663 - val_loss: 0.2076\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.2362 - val_loss: 0.1894\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.2175 - val_loss: 0.1702\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.2133 - val_loss: 0.1762\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 0s 42us/step - loss: 0.1982 - val_loss: 0.1723\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1992 - val_loss: 0.1566\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1860 - val_loss: 0.1551\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1787 - val_loss: 0.1557\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1737 - val_loss: 0.1508\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 0s 44us/step - loss: 0.1713 - val_loss: 0.1452\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1671 - val_loss: 0.1452\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1565 - val_loss: 0.1458\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1525 - val_loss: 0.1458\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 0s 41us/step - loss: 0.1525 - val_loss: 0.1438\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 1s 59us/step - loss: 0.1506 - val_loss: 0.1409\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 0s 52us/step - loss: 0.1457 - val_loss: 0.1505\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1412 - val_loss: 0.1409\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 0s 47us/step - loss: 0.1336 - val_loss: 0.1404\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 0s 43us/step - loss: 0.1318 - val_loss: 0.1327\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 0s 45us/step - loss: 0.1285 - val_loss: 0.1369\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.1221 - val_loss: 0.1338\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.1227 - val_loss: 0.1346\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.1182 - val_loss: 0.1335\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.1192 - val_loss: 0.1317\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 0s 48us/step - loss: 0.1160 - val_loss: 0.1388\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 0s 49us/step - loss: 0.1100 - val_loss: 0.1290\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 0s 54us/step - loss: 0.1069 - val_loss: 0.1320\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 0s 53us/step - loss: 0.1072 - val_loss: 0.1348\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 0s 50us/step - loss: 0.1061 - val_loss: 0.1337\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 0s 46us/step - loss: 0.0975 - val_loss: 0.1442\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 1s 57us/step - loss: 0.1003 - val_loss: 0.1334\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 1s 64us/step - loss: 0.0985 - val_loss: 0.1332\n",
      "MSE over 1000 samples on the run 2 : 0.1416 \n",
      "Mean of the MSE on 3 independant runs 0.1504 \n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "embedding_size = 50\n",
    "print(\"Embedding size : %d\" % (embedding_size))\n",
    "\n",
    "for i in range(0, 3) : \n",
    "\n",
    "    # Load the data\n",
    "    data = load_data(url_reset,params)\n",
    "    user_history = data[\"user_history\"]\n",
    "    item_history = data[\"item_history\"]\n",
    "    rating_history = data[\"rating_history\"]\n",
    "    train_ratings = pd.DataFrame({\"user_id\": user_history, \"item_id\": item_history, \"rating\": rating_history})\n",
    "\n",
    "    nb_users = data[\"nb_users\"]\n",
    "    nb_items = data[\"nb_items\"]\n",
    "    next_user = data[\"next_user\"]\n",
    "    next_item = data[\"next_item\"]\n",
    "\n",
    "    nb_samples = 1000\n",
    "    mse = 0\n",
    "\n",
    "    train_x = [train_ratings[\"user_id\"], train_ratings[\"item_id\"]]\n",
    "    train_y = train_ratings[\"rating\"]\n",
    "\n",
    "    model, history = recommender_system_deep_2(train_x, train_y, embedding_size, nb_users, nb_items)\n",
    "    \n",
    "    # For online learning \n",
    "    liste_users, liste_items, liste_rating = [], [], []\n",
    "    \n",
    "    for j in range(nb_samples) : \n",
    "        time.sleep(0.5)\n",
    "        prediction = model.predict([[next_user], [next_item]])[0][0]\n",
    "        params[\"predicted_score\"] = prediction\n",
    "        next_data = requests.get(url=url_predict, params=params).json()\n",
    "        rating = next_data[\"rating\"]\n",
    "        \n",
    "        liste_users.append(next_user)\n",
    "        liste_items.append(next_item)\n",
    "        liste_rating.append(rating)\n",
    "        if j%20 == 0 : \n",
    "            model.fit([liste_users, liste_items], liste_rating, verbose=False)\n",
    "            \n",
    "        next_user = next_data[\"next_user\"]\n",
    "        next_item = next_data[\"next_item\"]\n",
    "        mse += mean_square_error(rating, prediction)\n",
    "\n",
    "    mean += mse/nb_samples\n",
    "    print(\"MSE over 1000 samples on the run %d : %.4f \" % (i, mse/nb_samples))\n",
    "\n",
    "print(\"Mean of the MSE on 3 independant runs %.4f \" % (mean/3))\n",
    "print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font color='blue'>\n",
    "    It is not bad compared to the first one. So, we should do online learning with a pack of 20 or more predictions not only 1 new prediction.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Conclusion \n",
    "\n",
    "Our best model in the first environment is : \n",
    "- using a deep model with 2 Fully Connected layers\n",
    "- Embedding size = 50\n",
    "- Drop out = 0.3\n",
    "- We can add online learning\n",
    "\n",
    "- MSE over 1000 samples on the run 0 : 0.1321 \n",
    "- MSE over 1000 samples on the run 1 : 0.1062 \n",
    "- MSE over 1000 samples on the run 2 : 0.1049 \n",
    "- Mean of the MSE on 3 independant runs 0.1144 "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "First environment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
